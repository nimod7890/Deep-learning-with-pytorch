{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PSPNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Module\n",
    "### FeatureMap_convolution\n",
    "- input size : $3\\times 475\\times 475(c\\times h\\times w)$\n",
    "- output size : $128\\times 119\\times 119$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,bias):\n",
    "        super(conv2DBatchNormRelu,self).__init__()\n",
    "        self.conv=nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,dilation,bias=bias)\n",
    "        self.batchnorm=nn.BatchNorm2d(out_channels)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        x=self.batchnorm(x)\n",
    "        outputs=self.relu(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureMap_convolution,self).__init__()\n",
    "        in_channels,out_channels,kernel_size,stride,padding,dilation,bias=3,64,3,2,1,1,False\n",
    "        self.cbnr_1=conv2DBatchNormRelu(in_channels,out_channels,kernel_size,stride,padding,dilation,bias)\n",
    "\n",
    "        in_channels,out_channels,kernel_size,stride,padding,dilation,bias=64,64,3,1,1,1,False\n",
    "        self.cbnr_2=conv2DBatchNormRelu(in_channels,out_channels,kernel_size,stride,padding,dilation,bias)\n",
    "        \n",
    "        in_channels,out_channels,kernel_size,stride,padding,dilation,bias=64,128,3,1,1,1,False\n",
    "        self.cbnr_3=conv2DBatchNormRelu(in_channels,out_channels,kernel_size,stride,padding,dilation,bias)\n",
    "\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.cbnr_1(x)\n",
    "        x=self.cbnr_2(x)\n",
    "        x=self.cbnr_3(x)\n",
    "        outputs=self.maxpool(x)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 ResidualBlockPSP\n",
    "> skip connection(= shortcut connection = bypass): degradation 막기 위해 residual block\n",
    ">    - bottleNeckPSP: bypass에 conv 적용\n",
    ">    - bottleNeckIdentifyPSP: bypass에 conv 적용하지 않음\n",
    ">\n",
    "> dilation convolution: conv filter에 간격을 두어 적용\n",
    ">    - kernel size: filter간 간격\n",
    ">    - dilation convolution: filter 내 간격"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,bias):\n",
    "        super(conv2DBatchNorm,self).__init__()\n",
    "        self.conv=nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,dilation,bias=bias)\n",
    "        self.batchnorm=nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        outputs=self.batchnorm(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckPSP(nn.Module): \n",
    "    def __init__(self,in_channels,mid_channels,out_channels,stride,dilation):\n",
    "        super(bottleNeckPSP,self).__init__()\n",
    "        self.cbr_1=conv2DBatchNormRelu(in_channels,mid_channels,1,1,0,1,False)\n",
    "        self.cbr_2=conv2DBatchNormRelu(mid_channels,mid_channels,3,stride,dilation,dilation,False)\n",
    "        self.cbr_3=conv2DBatchNormRelu(mid_channels,out_channels,1,1,0,1,False)\n",
    "        \n",
    "        self.cb_residual=conv2DBatchNorm(in_channels,out_channels,1,stride,0,1,False) \n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv=self.cbr_3(self.cbr_2(self.cbr_1(x)))\n",
    "        residual=self.cb_residual(x)\n",
    "        return self.relu(conv+residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self,in_channels,mid_channels,dilation):\n",
    "        super(bottleNeckIdentifyPSP,self).__init__()\n",
    "        self.cbr_1=conv2DBatchNormRelu(in_channels,mid_channels,1,1,0,1,False)\n",
    "        self.cbr_2=conv2DBatchNormRelu(mid_channels,mid_channels,3,1,dilation,dilation,False)\n",
    "        self.cbr_3=conv2DBatchNorm(mid_channels,in_channels,1,1,0,1,False)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv=self.cbr_3(self.cbr_2(self.cbr_1(x)))\n",
    "        #x=residual\n",
    "        return self.relu(conv+x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockPSP(nn.Sequential): #nn.Sequential 상속 시 forward가 이미 구현되어 있음\n",
    "    def __init__(self,n_blocks,in_channels,mid_channels,out_channels,stride,dilation):\n",
    "        super(ResidualBlockPSP,self).__init__()\n",
    "        self.add_module(\"block1\",bottleNeckPSP(in_channels,mid_channels,out_channels,stride,dilation))\n",
    "        for i in range(n_blocks-1):\n",
    "            block_n=\"block\"+str(i+2)\n",
    "            self.add_module(block_n,bottleNeckIdentifyPSP(out_channels,mid_channels,dilation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyramid Pooling Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self,in_channels,pool_sizes,height,width):\n",
    "        super(PyramidPooling,self).__init__()\n",
    "        self.height=height\n",
    "        self.width=width\n",
    "        \n",
    "        out_channels=int(in_channels/len(pool_sizes))\n",
    "        self.avpool=[]\n",
    "        self.cbr=[]\n",
    "        for pool_size in pool_sizes:\n",
    "            self.avpool.append(nn.AdaptiveAvgPool2d(output_size=pool_size))\n",
    "            self.cbr.append(conv2DBatchNormRelu(in_channels,out_channels,1,1,0,1,False))\n",
    "\n",
    "    def forward(self,x):\n",
    "        outList=[x]\n",
    "        for pool,cbr in zip(self.avpool,self.cbr):\n",
    "            out=cbr(pool(x))\n",
    "            out=F.interpolate(out,size=(self.height,self.width),mode=\"bilinear\",align_corners=True)\n",
    "            outList.append(out)\n",
    "        output=torch.cat(outList,dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder,AuxLoss Module\n",
    "- decode tenser information\n",
    "- pixel 별로 class 분류\n",
    "- upsampling ($475\\times 475$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecoderPSPFeature Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodePSPFeature(nn.Module):\n",
    "    def __init__(self,height,width,n_classes):\n",
    "        super(DecodePSPFeature,self).__init__()\n",
    "        self.height=height\n",
    "        self.width=width\n",
    "\n",
    "        self.cbr=conv2DBatchNormRelu(4096,512,3,1,1,1,False)\n",
    "        self.dropout=nn.Dropout2d(p=0.1)\n",
    "        self.classification=nn.Conv2d(512,n_classes,1,1,0)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x=self.cbr(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.classification(x)\n",
    "        output=F.interpolate(x,size=(self.height,self.width),mode=\"bilinear\",align_corners=True)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AuxiliaryPSPLayers Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AuxiliaryPSPLayers(nn.Module):\n",
    "    def __init__(self,in_channels,height,width,n_classes):\n",
    "        super(AuxiliaryPSPLayers,self).__init__()\n",
    "        self.height=height\n",
    "        self.width=width\n",
    "        self.cbr=conv2DBatchNormRelu(in_channels,256,3,1,1,1,False)\n",
    "        self.dropout=nn.Dropout2d(p=0.1)\n",
    "        self.classification=nn.Conv2d(256,n_classes,1,1,0)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.cbr(x)\n",
    "        x=self.dropout(x)\n",
    "        x=self.classification(x)\n",
    "        output=F.interpolate(x,size=(self.height,self.width),mode=\"bilinear\",align_corners=True)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PSPNet Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super(PSPNet,self).__init__()\n",
    "        block_config=[3,4,6,3]\n",
    "        img_size=475\n",
    "        img_size_8=60 #img_size/8\n",
    "\n",
    "        self.feature_conv=FeatureMap_convolution()\n",
    "        self.feature_res_1=ResidualBlockPSP(block_config[0],128,64,256,1,1)\n",
    "        self.feature_res_2=ResidualBlockPSP(block_config[1],256,128,512,2,1)\n",
    "        self.feature_dilated_res_1=ResidualBlockPSP(block_config[2],512,256,1024,1,2)\n",
    "        self.feature_dilated_res_2=ResidualBlockPSP(block_config[3],1024,512,2048,1,4)\n",
    "\n",
    "        self.pyramid_pooling=PyramidPooling(2048,[6,3,2,1],img_size_8,img_size_8)\n",
    "        self.decode_feature=DecodePSPFeature(img_size,img_size,n_classes)\n",
    "        self.aux=AuxiliaryPSPLayers(1024,img_size,img_size,n_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "\n",
    "        x=self.feature_conv(x)\n",
    "        x=self.feature_res_1(x)\n",
    "        x=self.feature_res_2(x)\n",
    "        x=self.feature_dilated_res_1(x)\n",
    "        output_aux=self.aux(x)\n",
    "\n",
    "        x=self.feature_dilated_res_2(x)\n",
    "        x=self.pyramid_pooling(x)\n",
    "        output=self.decode_feature(x)\n",
    "\n",
    "        return (output,output_aux)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (feature_conv): FeatureMap_convolution(\n",
       "    (cbnr_1): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_2): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (cbnr_3): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (feature_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_1): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block4): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block5): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block6): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (feature_dilated_res_2): ResidualBlockPSP(\n",
       "    (block1): bottleNeckPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cb_residual): conv2DBatchNorm(\n",
       "        (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block2): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (block3): bottleNeckIdentifyPSP(\n",
       "      (cbr_1): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_2): conv2DBatchNormRelu(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (cbr_3): conv2DBatchNorm(\n",
       "        (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (batchnorm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pyramid_pooling): PyramidPooling()\n",
       "  (decode_feature): DecodePSPFeature(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(4096, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(512, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux): AuxiliaryPSPLayers(\n",
       "    (cbr): conv2DBatchNormRelu(\n",
       "      (conv): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (dropout): Dropout2d(p=0.1, inplace=False)\n",
       "    (classification): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=PSPNet(n_classes=21)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[-0.0914, -0.0021,  0.0873,  ..., -0.1116, -0.1086, -0.1055],\n",
      "          [-0.0872, -0.0076,  0.0719,  ..., -0.0750, -0.0671, -0.0593],\n",
      "          [-0.0829, -0.0132,  0.0565,  ..., -0.0383, -0.0257, -0.0130],\n",
      "          ...,\n",
      "          [ 0.3204,  0.3839,  0.4474,  ...,  0.2155,  0.2086,  0.2018],\n",
      "          [ 0.3114,  0.3884,  0.4655,  ...,  0.2434,  0.2361,  0.2289],\n",
      "          [ 0.3023,  0.3929,  0.4835,  ...,  0.2712,  0.2637,  0.2561]],\n",
      "\n",
      "         [[ 0.4771,  0.4641,  0.4511,  ...,  0.9820,  0.9808,  0.9796],\n",
      "          [ 0.5261,  0.5214,  0.5167,  ...,  0.9641,  0.9743,  0.9846],\n",
      "          [ 0.5751,  0.5788,  0.5824,  ...,  0.9461,  0.9679,  0.9896],\n",
      "          ...,\n",
      "          [ 1.1746,  1.0974,  1.0202,  ...,  1.1683,  1.1517,  1.1351],\n",
      "          [ 1.1943,  1.1152,  1.0362,  ...,  1.1776,  1.1525,  1.1274],\n",
      "          [ 1.2140,  1.1330,  1.0521,  ...,  1.1870,  1.1533,  1.1196]],\n",
      "\n",
      "         [[-0.0500, -0.1125, -0.1749,  ..., -0.3345, -0.3112, -0.2879],\n",
      "          [-0.0606, -0.1170, -0.1735,  ..., -0.2580, -0.2200, -0.1821],\n",
      "          [-0.0711, -0.1216, -0.1721,  ..., -0.1815, -0.1288, -0.0762],\n",
      "          ...,\n",
      "          [ 0.3116,  0.2537,  0.1959,  ...,  0.1995,  0.1853,  0.1711],\n",
      "          [ 0.2628,  0.2107,  0.1587,  ...,  0.1365,  0.1184,  0.1004],\n",
      "          [ 0.2140,  0.1677,  0.1215,  ...,  0.0736,  0.0516,  0.0297]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.5326, -0.4778, -0.4229,  ...,  0.0146,  0.0446,  0.0746],\n",
      "          [-0.4814, -0.4335, -0.3857,  ...,  0.0785,  0.1074,  0.1364],\n",
      "          [-0.4302, -0.3893, -0.3484,  ...,  0.1424,  0.1703,  0.1982],\n",
      "          ...,\n",
      "          [-0.3499, -0.2985, -0.2472,  ...,  0.0100,  0.0333,  0.0566],\n",
      "          [-0.3999, -0.3402, -0.2805,  ..., -0.0373, -0.0132,  0.0109],\n",
      "          [-0.4499, -0.3818, -0.3138,  ..., -0.0846, -0.0597, -0.0347]],\n",
      "\n",
      "         [[-0.1930, -0.2074, -0.2218,  ..., -0.5022, -0.5536, -0.6050],\n",
      "          [-0.1911, -0.2067, -0.2222,  ..., -0.4959, -0.5452, -0.5945],\n",
      "          [-0.1891, -0.2059, -0.2227,  ..., -0.4896, -0.5368, -0.5841],\n",
      "          ...,\n",
      "          [-0.7424, -0.7672, -0.7920,  ..., -0.5891, -0.5562, -0.5233],\n",
      "          [-0.7692, -0.7925, -0.8158,  ..., -0.5802, -0.5444, -0.5087],\n",
      "          [-0.7959, -0.8178, -0.8396,  ..., -0.5712, -0.5326, -0.4941]],\n",
      "\n",
      "         [[ 0.4474,  0.4515,  0.4555,  ...,  0.6620,  0.6839,  0.7058],\n",
      "          [ 0.3984,  0.3973,  0.3962,  ...,  0.6266,  0.6486,  0.6705],\n",
      "          [ 0.3494,  0.3431,  0.3369,  ...,  0.5913,  0.6132,  0.6351],\n",
      "          ...,\n",
      "          [ 0.5595,  0.5447,  0.5299,  ...,  0.9256,  0.9436,  0.9617],\n",
      "          [ 0.6108,  0.5914,  0.5720,  ...,  0.9511,  0.9697,  0.9883],\n",
      "          [ 0.6620,  0.6381,  0.6142,  ...,  0.9767,  0.9958,  1.0149]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2252,  0.2071,  0.1890,  ...,  0.3099,  0.3327,  0.3554],\n",
      "          [ 0.1901,  0.1852,  0.1804,  ...,  0.3005,  0.3231,  0.3456],\n",
      "          [ 0.1550,  0.1634,  0.1718,  ...,  0.2911,  0.3135,  0.3358],\n",
      "          ...,\n",
      "          [ 0.1334,  0.1452,  0.1570,  ...,  0.4354,  0.4478,  0.4601],\n",
      "          [ 0.0939,  0.1134,  0.1329,  ...,  0.4516,  0.4612,  0.4709],\n",
      "          [ 0.0543,  0.0816,  0.1088,  ...,  0.4677,  0.4746,  0.4816]],\n",
      "\n",
      "         [[ 0.6634,  0.6049,  0.5464,  ...,  1.1313,  1.1930,  1.2546],\n",
      "          [ 0.6666,  0.6083,  0.5499,  ...,  1.1167,  1.1721,  1.2274],\n",
      "          [ 0.6698,  0.6116,  0.5535,  ...,  1.1021,  1.1512,  1.2003],\n",
      "          ...,\n",
      "          [ 1.0817,  1.0998,  1.1180,  ...,  1.5444,  1.6152,  1.6860],\n",
      "          [ 1.0844,  1.1077,  1.1311,  ...,  1.5770,  1.6541,  1.7313],\n",
      "          [ 1.0871,  1.1156,  1.1441,  ...,  1.6095,  1.6930,  1.7765]],\n",
      "\n",
      "         [[ 0.0660, -0.0183, -0.1025,  ...,  0.1721,  0.2304,  0.2887],\n",
      "          [ 0.0438, -0.0236, -0.0911,  ...,  0.2147,  0.2713,  0.3279],\n",
      "          [ 0.0217, -0.0290, -0.0796,  ...,  0.2573,  0.3122,  0.3671],\n",
      "          ...,\n",
      "          [ 0.4711,  0.4120,  0.3529,  ...,  0.2412,  0.2496,  0.2579],\n",
      "          [ 0.5330,  0.4625,  0.3921,  ...,  0.2000,  0.2138,  0.2276],\n",
      "          [ 0.5949,  0.5131,  0.4312,  ...,  0.1588,  0.1781,  0.1973]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.6066, -0.5294, -0.4522,  ..., -0.3846, -0.4018, -0.4191],\n",
      "          [-0.6063, -0.5220, -0.4378,  ..., -0.3303, -0.3405, -0.3508],\n",
      "          [-0.6060, -0.5147, -0.4234,  ..., -0.2760, -0.2792, -0.2825],\n",
      "          ...,\n",
      "          [-0.1750, -0.1258, -0.0767,  ..., -0.0225, -0.0218, -0.0211],\n",
      "          [-0.2089, -0.1557, -0.1025,  ..., -0.0710, -0.0669, -0.0627],\n",
      "          [-0.2428, -0.1855, -0.1283,  ..., -0.1195, -0.1119, -0.1043]],\n",
      "\n",
      "         [[ 0.0428,  0.0784,  0.1140,  ..., -0.1862, -0.2124, -0.2387],\n",
      "          [ 0.0291,  0.0703,  0.1115,  ..., -0.1808, -0.1991, -0.2174],\n",
      "          [ 0.0154,  0.0622,  0.1090,  ..., -0.1755, -0.1858, -0.1961],\n",
      "          ...,\n",
      "          [-0.5941, -0.5999, -0.6056,  ..., -0.4752, -0.4165, -0.3577],\n",
      "          [-0.6053, -0.6213, -0.6372,  ..., -0.4837, -0.4230, -0.3623],\n",
      "          [-0.6165, -0.6427, -0.6688,  ..., -0.4921, -0.4295, -0.3668]],\n",
      "\n",
      "         [[ 0.4956,  0.4796,  0.4637,  ...,  0.4131,  0.4080,  0.4028],\n",
      "          [ 0.4700,  0.4509,  0.4318,  ...,  0.3960,  0.3928,  0.3896],\n",
      "          [ 0.4444,  0.4222,  0.3999,  ...,  0.3789,  0.3776,  0.3763],\n",
      "          ...,\n",
      "          [ 0.6841,  0.7072,  0.7303,  ...,  0.9379,  0.9527,  0.9676],\n",
      "          [ 0.6516,  0.6749,  0.6983,  ...,  0.9208,  0.9289,  0.9369],\n",
      "          [ 0.6192,  0.6427,  0.6662,  ...,  0.9038,  0.9050,  0.9063]]]],\n",
      "       grad_fn=<UpsampleBilinear2DBackward1>), tensor([[[[-5.5786e-01, -5.6944e-01, -5.8102e-01,  ..., -6.3166e-01,\n",
      "           -7.3158e-01, -8.3150e-01],\n",
      "          [-4.9845e-01, -5.1051e-01, -5.2257e-01,  ..., -6.0181e-01,\n",
      "           -6.8532e-01, -7.6883e-01],\n",
      "          [-4.3904e-01, -4.5157e-01, -4.6411e-01,  ..., -5.7197e-01,\n",
      "           -6.3906e-01, -7.0616e-01],\n",
      "          ...,\n",
      "          [-7.9262e-01, -7.5753e-01, -7.2243e-01,  ..., -7.4650e-01,\n",
      "           -8.0936e-01, -8.7223e-01],\n",
      "          [-8.0082e-01, -7.5959e-01, -7.1836e-01,  ..., -8.0003e-01,\n",
      "           -8.6992e-01, -9.3980e-01],\n",
      "          [-8.0902e-01, -7.6165e-01, -7.1428e-01,  ..., -8.5356e-01,\n",
      "           -9.3047e-01, -1.0074e+00]],\n",
      "\n",
      "         [[-7.6599e-01, -6.8776e-01, -6.0953e-01,  ..., -2.1015e-01,\n",
      "           -1.4420e-01, -7.8241e-02],\n",
      "          [-7.1061e-01, -6.3860e-01, -5.6659e-01,  ..., -1.8113e-01,\n",
      "           -1.3182e-01, -8.2502e-02],\n",
      "          [-6.5524e-01, -5.8945e-01, -5.2365e-01,  ..., -1.5211e-01,\n",
      "           -1.1944e-01, -8.6762e-02],\n",
      "          ...,\n",
      "          [-2.8354e-01, -2.5153e-01, -2.1953e-01,  ..., -2.2291e-01,\n",
      "           -2.7114e-01, -3.1937e-01],\n",
      "          [-3.0523e-01, -2.7284e-01, -2.4044e-01,  ..., -1.9393e-01,\n",
      "           -2.4919e-01, -3.0446e-01],\n",
      "          [-3.2693e-01, -2.9414e-01, -2.6135e-01,  ..., -1.6495e-01,\n",
      "           -2.2725e-01, -2.8955e-01]],\n",
      "\n",
      "         [[-1.6133e-01, -1.8003e-01, -1.9872e-01,  ..., -7.2477e-01,\n",
      "           -7.4435e-01, -7.6392e-01],\n",
      "          [-1.8380e-01, -2.0652e-01, -2.2925e-01,  ..., -6.3767e-01,\n",
      "           -6.6363e-01, -6.8960e-01],\n",
      "          [-2.0627e-01, -2.3302e-01, -2.5977e-01,  ..., -5.5057e-01,\n",
      "           -5.8292e-01, -6.1528e-01],\n",
      "          ...,\n",
      "          [-5.1692e-01, -4.8127e-01, -4.4562e-01,  ..., -5.0274e-01,\n",
      "           -5.2240e-01, -5.4207e-01],\n",
      "          [-4.9299e-01, -4.5244e-01, -4.1189e-01,  ..., -5.2352e-01,\n",
      "           -5.4170e-01, -5.5988e-01],\n",
      "          [-4.6905e-01, -4.2361e-01, -3.7817e-01,  ..., -5.4429e-01,\n",
      "           -5.6099e-01, -5.7769e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7277e-02, -7.3193e-02, -8.9108e-02,  ...,  2.5597e-01,\n",
      "            2.8723e-01,  3.1849e-01],\n",
      "          [ 3.9371e-03, -1.0404e-02, -2.4746e-02,  ...,  2.6605e-01,\n",
      "            2.9649e-01,  3.2693e-01],\n",
      "          [ 6.5152e-02,  5.2384e-02,  3.9616e-02,  ...,  2.7613e-01,\n",
      "            3.0575e-01,  3.3537e-01],\n",
      "          ...,\n",
      "          [-2.6582e-01, -2.1298e-01, -1.6013e-01,  ...,  4.6902e-01,\n",
      "            4.8863e-01,  5.0824e-01],\n",
      "          [-2.4241e-01, -1.8655e-01, -1.3069e-01,  ...,  4.5769e-01,\n",
      "            4.9025e-01,  5.2282e-01],\n",
      "          [-2.1900e-01, -1.6012e-01, -1.0124e-01,  ...,  4.4636e-01,\n",
      "            4.9188e-01,  5.3740e-01]],\n",
      "\n",
      "         [[ 1.1602e+00,  1.1426e+00,  1.1251e+00,  ...,  6.1059e-01,\n",
      "            5.1757e-01,  4.2456e-01],\n",
      "          [ 1.1413e+00,  1.1222e+00,  1.1031e+00,  ...,  6.0772e-01,\n",
      "            5.3424e-01,  4.6075e-01],\n",
      "          [ 1.1224e+00,  1.1018e+00,  1.0811e+00,  ...,  6.0486e-01,\n",
      "            5.5090e-01,  4.9695e-01],\n",
      "          ...,\n",
      "          [ 1.0655e+00,  1.0296e+00,  9.9365e-01,  ...,  1.1762e+00,\n",
      "            1.2052e+00,  1.2342e+00],\n",
      "          [ 1.0593e+00,  1.0274e+00,  9.9555e-01,  ...,  1.2202e+00,\n",
      "            1.2574e+00,  1.2946e+00],\n",
      "          [ 1.0531e+00,  1.0253e+00,  9.9744e-01,  ...,  1.2642e+00,\n",
      "            1.3095e+00,  1.3549e+00]],\n",
      "\n",
      "         [[-1.4570e-01, -1.6571e-01, -1.8573e-01,  ..., -4.4861e-01,\n",
      "           -4.4819e-01, -4.4777e-01],\n",
      "          [-1.4116e-01, -1.6346e-01, -1.8577e-01,  ..., -4.0769e-01,\n",
      "           -4.0923e-01, -4.1077e-01],\n",
      "          [-1.3661e-01, -1.6121e-01, -1.8581e-01,  ..., -3.6676e-01,\n",
      "           -3.7027e-01, -3.7377e-01],\n",
      "          ...,\n",
      "          [-2.0459e-01, -1.8837e-01, -1.7216e-01,  ..., -3.2558e-01,\n",
      "           -3.0478e-01, -2.8397e-01],\n",
      "          [-1.6153e-01, -1.4984e-01, -1.3816e-01,  ..., -2.7610e-01,\n",
      "           -2.4946e-01, -2.2282e-01],\n",
      "          [-1.1846e-01, -1.1131e-01, -1.0416e-01,  ..., -2.2661e-01,\n",
      "           -1.9414e-01, -1.6168e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.2920e-01, -4.5231e-01, -3.7543e-01,  ..., -3.8503e-01,\n",
      "           -3.9468e-01, -4.0433e-01],\n",
      "          [-5.1792e-01, -4.4439e-01, -3.7085e-01,  ..., -3.7367e-01,\n",
      "           -3.7210e-01, -3.7052e-01],\n",
      "          [-5.0664e-01, -4.3646e-01, -3.6628e-01,  ..., -3.6232e-01,\n",
      "           -3.4951e-01, -3.3670e-01],\n",
      "          ...,\n",
      "          [-7.9005e-01, -7.2741e-01, -6.6477e-01,  ..., -5.4785e-01,\n",
      "           -5.8786e-01, -6.2786e-01],\n",
      "          [-7.6524e-01, -7.1347e-01, -6.6170e-01,  ..., -5.6293e-01,\n",
      "           -6.0665e-01, -6.5038e-01],\n",
      "          [-7.4042e-01, -6.9952e-01, -6.5862e-01,  ..., -5.7800e-01,\n",
      "           -6.2545e-01, -6.7290e-01]],\n",
      "\n",
      "         [[-4.2608e-01, -3.2258e-01, -2.1907e-01,  ..., -1.0674e-01,\n",
      "           -8.7854e-02, -6.8966e-02],\n",
      "          [-3.9844e-01, -3.0313e-01, -2.0781e-01,  ..., -1.4546e-01,\n",
      "           -1.2722e-01, -1.0897e-01],\n",
      "          [-3.7080e-01, -2.8367e-01, -1.9654e-01,  ..., -1.8419e-01,\n",
      "           -1.6658e-01, -1.4897e-01],\n",
      "          ...,\n",
      "          [-1.2257e-01, -1.7018e-01, -2.1779e-01,  ..., -1.1625e-01,\n",
      "           -1.3531e-01, -1.5436e-01],\n",
      "          [-1.2974e-01, -1.8423e-01, -2.3872e-01,  ..., -7.5271e-02,\n",
      "           -8.6684e-02, -9.8096e-02],\n",
      "          [-1.3692e-01, -1.9828e-01, -2.5965e-01,  ..., -3.4287e-02,\n",
      "           -3.8061e-02, -4.1836e-02]],\n",
      "\n",
      "         [[-7.8090e-02, -7.7458e-02, -7.6826e-02,  ..., -4.3914e-01,\n",
      "           -4.2208e-01, -4.0502e-01],\n",
      "          [-1.0233e-01, -1.0559e-01, -1.0885e-01,  ..., -4.4744e-01,\n",
      "           -4.3543e-01, -4.2342e-01],\n",
      "          [-1.2656e-01, -1.3372e-01, -1.4087e-01,  ..., -4.5573e-01,\n",
      "           -4.4878e-01, -4.4183e-01],\n",
      "          ...,\n",
      "          [-1.2417e-01, -1.9886e-01, -2.7356e-01,  ..., -6.6613e-02,\n",
      "           -3.8628e-02, -1.0642e-02],\n",
      "          [-1.3419e-01, -2.0577e-01, -2.7735e-01,  ..., -4.4456e-02,\n",
      "            3.4556e-04,  4.5148e-02],\n",
      "          [-1.4422e-01, -2.1268e-01, -2.8114e-01,  ..., -2.2300e-02,\n",
      "            3.9319e-02,  1.0094e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7392e-01, -2.4265e-01, -2.1139e-01,  ...,  2.7995e-01,\n",
      "            2.4186e-01,  2.0378e-01],\n",
      "          [-2.6543e-01, -2.2863e-01, -1.9183e-01,  ...,  2.9551e-01,\n",
      "            2.5409e-01,  2.1267e-01],\n",
      "          [-2.5694e-01, -2.1461e-01, -1.7228e-01,  ...,  3.1107e-01,\n",
      "            2.6631e-01,  2.2156e-01],\n",
      "          ...,\n",
      "          [-2.8009e-01, -2.6436e-01, -2.4863e-01,  ...,  4.2831e-02,\n",
      "            4.4188e-02,  4.5545e-02],\n",
      "          [-2.1401e-01, -2.0793e-01, -2.0185e-01,  ...,  2.2735e-02,\n",
      "            3.3713e-02,  4.4691e-02],\n",
      "          [-1.4793e-01, -1.5150e-01, -1.5507e-01,  ...,  2.6390e-03,\n",
      "            2.3238e-02,  4.3837e-02]],\n",
      "\n",
      "         [[ 1.1331e+00,  1.0566e+00,  9.8000e-01,  ...,  5.0418e-01,\n",
      "            4.9954e-01,  4.9491e-01],\n",
      "          [ 1.0643e+00,  9.9823e-01,  9.3213e-01,  ...,  5.6747e-01,\n",
      "            5.6546e-01,  5.6345e-01],\n",
      "          [ 9.9551e-01,  9.3988e-01,  8.8426e-01,  ...,  6.3077e-01,\n",
      "            6.3138e-01,  6.3200e-01],\n",
      "          ...,\n",
      "          [ 8.9587e-01,  8.7534e-01,  8.5480e-01,  ...,  8.7067e-01,\n",
      "            8.8747e-01,  9.0428e-01],\n",
      "          [ 9.0576e-01,  8.9088e-01,  8.7601e-01,  ...,  8.5323e-01,\n",
      "            8.7375e-01,  8.9427e-01],\n",
      "          [ 9.1564e-01,  9.0643e-01,  8.9721e-01,  ...,  8.3580e-01,\n",
      "            8.6003e-01,  8.8426e-01]],\n",
      "\n",
      "         [[-2.2006e-01, -2.7928e-01, -3.3850e-01,  ..., -4.5690e-01,\n",
      "           -4.8737e-01, -5.1783e-01],\n",
      "          [-2.9105e-01, -3.3925e-01, -3.8744e-01,  ..., -4.4367e-01,\n",
      "           -4.7054e-01, -4.9740e-01],\n",
      "          [-3.6205e-01, -3.9922e-01, -4.3639e-01,  ..., -4.3044e-01,\n",
      "           -4.5370e-01, -4.7697e-01],\n",
      "          ...,\n",
      "          [-3.9427e-01, -3.8554e-01, -3.7680e-01,  ..., -1.8965e-02,\n",
      "           -2.9424e-02, -3.9884e-02],\n",
      "          [-3.5136e-01, -3.4576e-01, -3.4015e-01,  ..., -1.9019e-02,\n",
      "           -4.0801e-02, -6.2584e-02],\n",
      "          [-3.0845e-01, -3.0598e-01, -3.0350e-01,  ..., -1.9073e-02,\n",
      "           -5.2179e-02, -8.5284e-02]]]], grad_fn=<UpsampleBilinear2DBackward1>))\n"
     ]
    }
   ],
   "source": [
    "'''check'''\n",
    "batch_size=2\n",
    "dummy_img=torch.rand(batch_size,3,475,475)\n",
    "outputs=net(dummy_img)\n",
    "print(outputs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "415c659548b03e5a7ab126dcfbb4fc7162127f64c5d6abf067896d088a8939b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorchDeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
