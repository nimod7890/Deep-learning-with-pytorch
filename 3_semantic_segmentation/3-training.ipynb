{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import makeDatapathList,dataTransform,VOCDataset\n",
    "\n",
    "root_path=\"./data/VOCdevkit/VOC2012/\"\n",
    "\n",
    "datapath_list=makeDatapathList(root_path)\n",
    "train_img_list,train_anno_list=datapath_list('train')\n",
    "val_img_list,val_anno_list=datapath_list('val')\n",
    "\n",
    "color_mean=(0.485,0.456,0.406)\n",
    "color_std=(0.29,0.224,0.225)\n",
    "\n",
    "transform=dataTransform(475,color_mean,color_std)\n",
    "train_dataset=VOCDataset(train_img_list,train_anno_list,phase=\"train\",transform=transform)\n",
    "val_dataset=VOCDataset(val_img_list,val_anno_list,phase=\"val\",transform=transform)\n",
    "\n",
    "batch_size=4\n",
    "train_dataloader=data.DataLoader(train_dataset,batch_size,True)\n",
    "val_dataloader=data.DataLoader(val_dataset,batch_size,False)\n",
    "\n",
    "dataloaders_dict={\"train\":train_dataloader,\"val\":val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pspnet import PSPNet\n",
    "\n",
    "net=PSPNet(n_classes=150)\n",
    "\n",
    "state_dict=torch.load(\"./weights/pspnet50_ADE20K.pth\") #fine tuning\n",
    "net.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "n_classes=21\n",
    "net.decode_feature.classification=nn.Conv2d(in_channels=512,out_channels=n_classes,kernel_size=1,stride=1,padding=0)\n",
    "net.aux.classification=nn.Conv2d(in_channels=256,out_channels=n_classes,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m,nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias,0.0)\n",
    "\n",
    "net.decode_feature.classification.apply(weights_init)\n",
    "net.aux.classification.apply(weights_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPLoss(nn.Module):\n",
    "    def __init__(self,aux_weight=0.4):\n",
    "        super(PSPLoss,self).__init__()\n",
    "        self.aux_weight=aux_weight\n",
    "    \n",
    "    def forward(self,outputs,targets):\n",
    "        loss=F.cross_entropy(outputs[0],targets,reduction='mean')\n",
    "        loss_aux=F.cross_entropy(outputs[1],targets,reduction='mean')\n",
    "        return loss+self.aux_weight*loss_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=PSPLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD([\n",
    "    {'params':net.feature_conv.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_res_1.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_res_2.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_dilated_res_1.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_dilated_res_2.parameters(),'lr':1e-3},\n",
    "    {'params':net.pyramid_pooling.parameters(),'lr':1e-3},\n",
    "    {'params':net.decode_feature.parameters(),'lr':1e-3},\n",
    "    {'params':net.aux.parameters(),'lr':1e-3},\n",
    "],momentum=0.9,weight_decay=0.0001)\n",
    "\n",
    "def lambda_epoch(epoch):\n",
    "    max_epoch=30\n",
    "    return math.pow((1-epoch/max_epoch),0.9)\n",
    "\n",
    "scheduler=optim.lr_scheduler.LambdaLR(optimizer,lr_lambda=lambda_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net,dataloaders_dict,criterion,scheduler,optimizer,num_epochs):\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    num_train_imgs=len(dataloaders_dict[\"train\"].dataset)\n",
    "    num_val_imgs=len(dataloaders_dict[\"val\"].dataset)\n",
    "    \n",
    "    batch_size=dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    iteration=1\n",
    "    logs=[]\n",
    "\n",
    "    batch_multiplier=3\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        t_epoch_start=time.time()\n",
    "        t_iter_start=time.time()\n",
    "        epoch_train_loss=0.0\n",
    "        epoch_val_loss=0.0\n",
    "\n",
    "        print(f\"{'='*5}Epoch {epoch+1}/{num_epochs}{'='*5}\")\n",
    "        for phase in [\"train\",\"val\"]:\n",
    "            if phase==\"train\":\n",
    "                net.train()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                print(\"[train]\")\n",
    "            else:\n",
    "                if (epoch+1)%5==0:\n",
    "                    net.eval()\n",
    "                    print(\"[val]\")\n",
    "                else: \n",
    "                    continue\n",
    "            count=0\n",
    "            for imgs,anno_class_imgs in dataloaders_dict[phase]:\n",
    "                if imgs.size()[0]==1:\n",
    "                    continue\n",
    "                imgs=imgs.to(device)\n",
    "                anno_class_imgs=anno_class_imgs.to(device)\n",
    "\n",
    "                if phase=='train' and count==0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    count=batch_multiplier\n",
    "                    with torch.set_grad_enabled(phase==\"train\"):\n",
    "                        outputs=net(imgs)\n",
    "                        loss=criterion(outputs,anno_class_imgs.long())/batch_multiplier\n",
    "                        if phase==\"train\":\n",
    "                            loss.backward()\n",
    "                            count-=1\n",
    "                            if iteration%10==0:\n",
    "                                t_iter_finish=time.time()\n",
    "                                print(\"iter [{}] loss:{:.4f}   | {:.4f}sec\".format(iteration,loss.item()/batch_size*batch_multiplier,t_iter_finish-t_iter_start))\n",
    "                                t_iter_start=time.time()\n",
    "                            epoch_train_loss+=loss.item()*batch_multiplier\n",
    "                            iteration+=1\n",
    "                        else:\n",
    "                            epoch_val_loss+=loss.item()*batch_multiplier\n",
    "            t_epoch_finish=time.time()\n",
    "            print(\"epoch [{}] train loss:{:.4f}, val loss:{:.4f}  | {:.4f}sec\".format(iteration,epoch_train_loss/num_train_imgs,epoch_val_loss/num_val_imgs,t_epoch_finish-t_epoch_start))\n",
    "            t_epoch_start=time.time()\n",
    "\n",
    "            log_epoch={'epoch':epoch+1,'train_loss':epoch_train_loss/num_train_imgs,'val_loss':epoch_val_loss/num_val_imgs}\n",
    "            logs.append(log_epoch)\n",
    "            df=pd.DataFrame(logs)\n",
    "            df.to_csv('log_output.csv')\n",
    "        torch.save(net.state_dict(),'weights/pspnet50_'+str(epoch+1)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "=====Epoch 1/30=====\n",
      "[train]\n",
      "epoch [2] train loss:0.0032, val loss:0.0000  | 29.6834sec\n",
      "=====Epoch 2/30=====\n",
      "[train]\n",
      "epoch [3] train loss:0.0032, val loss:0.0000  | 26.8674sec\n",
      "=====Epoch 3/30=====\n",
      "[train]\n",
      "epoch [4] train loss:0.0033, val loss:0.0000  | 26.8150sec\n",
      "=====Epoch 4/30=====\n",
      "[train]\n",
      "epoch [5] train loss:0.0032, val loss:0.0000  | 26.7496sec\n",
      "=====Epoch 5/30=====\n",
      "[train]\n",
      "epoch [6] train loss:0.0034, val loss:0.0000  | 26.8550sec\n",
      "[val]\n",
      "epoch [6] train loss:0.0034, val loss:0.0000  | 14.2387sec\n",
      "=====Epoch 6/30=====\n",
      "[train]\n",
      "epoch [7] train loss:0.0032, val loss:0.0000  | 26.7391sec\n",
      "=====Epoch 7/30=====\n",
      "[train]\n",
      "epoch [8] train loss:0.0033, val loss:0.0000  | 26.7467sec\n",
      "=====Epoch 8/30=====\n",
      "[train]\n",
      "epoch [9] train loss:0.0031, val loss:0.0000  | 26.6929sec\n",
      "=====Epoch 9/30=====\n",
      "[train]\n",
      "epoch [10] train loss:0.0034, val loss:0.0000  | 26.7400sec\n",
      "=====Epoch 10/30=====\n",
      "[train]\n",
      "iter [10] loss:1.2985   | 0.1271sec\n",
      "epoch [11] train loss:0.0035, val loss:0.0000  | 26.9709sec\n",
      "[val]\n",
      "epoch [11] train loss:0.0035, val loss:0.0000  | 14.2379sec\n",
      "=====Epoch 11/30=====\n",
      "[train]\n",
      "epoch [12] train loss:0.0032, val loss:0.0000  | 26.7308sec\n",
      "=====Epoch 12/30=====\n",
      "[train]\n",
      "epoch [13] train loss:0.0034, val loss:0.0000  | 26.7852sec\n",
      "=====Epoch 13/30=====\n",
      "[train]\n",
      "epoch [14] train loss:0.0032, val loss:0.0000  | 26.7665sec\n",
      "=====Epoch 14/30=====\n",
      "[train]\n",
      "epoch [15] train loss:0.0031, val loss:0.0000  | 26.7241sec\n",
      "=====Epoch 15/30=====\n",
      "[train]\n",
      "epoch [16] train loss:0.0030, val loss:0.0000  | 26.8343sec\n",
      "[val]\n",
      "epoch [16] train loss:0.0030, val loss:0.0000  | 14.1600sec\n",
      "=====Epoch 16/30=====\n",
      "[train]\n",
      "epoch [17] train loss:0.0033, val loss:0.0000  | 26.8223sec\n",
      "=====Epoch 17/30=====\n",
      "[train]\n",
      "epoch [18] train loss:0.0035, val loss:0.0000  | 26.8805sec\n",
      "=====Epoch 18/30=====\n",
      "[train]\n",
      "epoch [19] train loss:0.0031, val loss:0.0000  | 26.7646sec\n",
      "=====Epoch 19/30=====\n",
      "[train]\n",
      "epoch [20] train loss:0.0033, val loss:0.0000  | 26.7963sec\n",
      "=====Epoch 20/30=====\n",
      "[train]\n",
      "iter [20] loss:1.2612   | 0.1102sec\n",
      "epoch [21] train loss:0.0034, val loss:0.0000  | 26.8809sec\n",
      "[val]\n",
      "epoch [21] train loss:0.0034, val loss:0.0000  | 14.2403sec\n",
      "=====Epoch 21/30=====\n",
      "[train]\n",
      "epoch [22] train loss:0.0035, val loss:0.0000  | 27.0615sec\n",
      "=====Epoch 22/30=====\n",
      "[train]\n",
      "epoch [23] train loss:0.0032, val loss:0.0000  | 26.9345sec\n",
      "=====Epoch 23/30=====\n",
      "[train]\n",
      "epoch [24] train loss:0.0032, val loss:0.0000  | 27.4703sec\n",
      "=====Epoch 24/30=====\n",
      "[train]\n",
      "epoch [25] train loss:0.0032, val loss:0.0000  | 27.0142sec\n",
      "=====Epoch 25/30=====\n",
      "[train]\n",
      "epoch [26] train loss:0.0033, val loss:0.0000  | 26.8938sec\n",
      "[val]\n",
      "epoch [26] train loss:0.0033, val loss:0.0000  | 14.5234sec\n",
      "=====Epoch 26/30=====\n",
      "[train]\n",
      "epoch [27] train loss:0.0033, val loss:0.0000  | 26.7868sec\n",
      "=====Epoch 27/30=====\n",
      "[train]\n",
      "epoch [28] train loss:0.0032, val loss:0.0000  | 26.7775sec\n",
      "=====Epoch 28/30=====\n",
      "[train]\n",
      "epoch [29] train loss:0.0034, val loss:0.0000  | 26.7784sec\n",
      "=====Epoch 29/30=====\n",
      "[train]\n",
      "epoch [30] train loss:0.0033, val loss:0.0000  | 26.8383sec\n",
      "=====Epoch 30/30=====\n",
      "[train]\n",
      "iter [30] loss:1.2134   | 0.1081sec\n",
      "epoch [31] train loss:0.0033, val loss:0.0000  | 26.7008sec\n",
      "[val]\n",
      "epoch [31] train loss:0.0033, val loss:0.0000  | 14.2708sec\n"
     ]
    }
   ],
   "source": [
    "num_epochs=30\n",
    "train_model(net,dataloaders_dict,criterion,scheduler,optimizer,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "415c659548b03e5a7ab126dcfbb4fc7162127f64c5d6abf067896d088a8939b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorchDeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
