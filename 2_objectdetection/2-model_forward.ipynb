{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "from math import sqrt\n",
    "from itertools import product\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGGModule():\n",
    "    layers=[]\n",
    "    #faster than list()\n",
    "    in_channels=3\n",
    "    cfg=[64,64,'M',128,128,'M',256,256,256,'MC',512,512,512,'M',512,512,512]\n",
    "    for v in cfg:\n",
    "        if v=='M':\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2,stride=2))\n",
    "            # faster than '+='\n",
    "        elif v=='MC':\n",
    "            layers.append(nn.MaxPool2d(kernel_size=2,stride=2,ceil_mode=True))\n",
    "            #ceil mode: float 올림\n",
    "            #floor mode(default): float 내림\n",
    "        else:\n",
    "            layers+=[\n",
    "                nn.Conv2d(in_channels,v,kernel_size=3,padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            #faster than .extend()\n",
    "            in_channels=v\n",
    "    \n",
    "    layers+=[\n",
    "        nn.MaxPool2d(kernel_size=3,stride=1,padding=1),\n",
    "        nn.Conv2d(512,1024,kernel_size=3,padding=6,dilation=6),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(1024,1024,kernel_size=1),\n",
    "        nn.ReLU(inplace=True)]\n",
    "    return nn.ModuleList(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       "  (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "  (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "  (32): ReLU(inplace=True)\n",
       "  (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (34): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''check'''\n",
    "VGGModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extra module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrasModule():\n",
    "    in_channels=1024 #output of vgg module\n",
    "    cfg=[256,512,128,256,128,256,128,256]\n",
    "    layers=[\n",
    "        nn.Conv2d(in_channels,cfg[0],kernel_size=(1)),\n",
    "        nn.Conv2d(cfg[0],cfg[1],kernel_size=(3),stride=2,padding=1),\n",
    "        nn.Conv2d(cfg[1],cfg[2],kernel_size=(1)),\n",
    "        nn.Conv2d(cfg[2],cfg[3],kernel_size=(3),stride=2,padding=1),\n",
    "        nn.Conv2d(cfg[3],cfg[4],kernel_size=(1)),\n",
    "        nn.Conv2d(cfg[4],cfg[5],kernel_size=(3)),\n",
    "        nn.Conv2d(cfg[5],cfg[6],kernel_size=(1)),\n",
    "        nn.Conv2d(cfg[6],cfg[7],kernel_size=(3)),\n",
    "    ]\n",
    "    #activation function(ReLU)은 foward propagation 부분에서\n",
    "    return nn.ModuleList(layers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''check'''\n",
    "extrasModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc conf module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locConfModule(num_classes=21,bbox_aspect_num=[4,6,6,6,4,4]):\n",
    "\n",
    "    loc_layers,conf_layers=[],[]\n",
    "    cfg=[512,1024,512,256,256,256]\n",
    "    \n",
    "    for idx,v in enumerate(cfg):\n",
    "        loc_layers.append(nn.Conv2d(v,bbox_aspect_num[idx]*4,kernel_size=3,padding=1))\n",
    "        conf_layers.append(nn.Conv2d(v,bbox_aspect_num[idx]*num_classes,kernel_size=3,padding=1))\n",
    "\n",
    "    return nn.ModuleList(loc_layers),nn.ModuleList(conf_layers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ModuleList(\n",
       "   (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ),\n",
       " ModuleList(\n",
       "   (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       " ))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''check'''\n",
    "locConfModule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 Norm layer\n",
    "- 채널 방향 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Norm(nn.Module):\n",
    "    \n",
    "    def __init__(self,input_channels=512,scale=20):\n",
    "        super(L2Norm,self).__init__()\n",
    "        self.weight=nn.Parameter(torch.Tensor(input_channels))\n",
    "        self.scale=scale\n",
    "        self.reset_parameters()\n",
    "        self.eps=1e-10\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        init.constant_(self.weight,self.scale)\n",
    "\n",
    "    def forward(self,x):\n",
    "        norm=x.pow(2).sum(dim=1,keepdim=True).sqrt()+self.eps\n",
    "        x=torch.div(x,norm)\n",
    "    \n",
    "        weights=self.weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        out=weights*x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Box Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBox(object):\n",
    "    def __init__(self,cfg):\n",
    "        super(DBox,self.__init())\n",
    "        self.image_size=cfg['input_size']\n",
    "        self.feature_maps=cfg['feature_maps']\n",
    "        self.num_priors=len(cfg['feature_maps'])\n",
    "        self.steps=cfg['steps']\n",
    "        self.min_sizes=cfg['min_sizes']\n",
    "        self.max_sizes=cfg['max_sizes']\n",
    "        self.aspect_ratios=cfg['aspect_ratios']\n",
    "    \n",
    "    def make_dbox_list(self):\n",
    "        for k,f in enumerate(self.feature_maps):\n",
    "            for i,j in product(range(f),repeat=2):\n",
    "                f_k=self.image_size/self.steps[k]\n",
    "\n",
    "                c_x,c_y=(j+0.5)/f_k,(i+0.5)/f_k\n",
    "                s_k=self.min_sizes[k]/self.image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "415c659548b03e5a7ab126dcfbb4fc7162127f64c5d6abf067896d088a8939b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorchDeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
