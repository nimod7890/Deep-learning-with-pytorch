{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import makeDatapathList,dataTransform,VOCDataset\n",
    "\n",
    "root_path=\"./data/VOCdevkit/VOC2012/\"\n",
    "\n",
    "datapath_list=makeDatapathList(root_path)\n",
    "train_img_list,train_anno_list=datapath_list('train')\n",
    "val_img_list,val_anno_list=datapath_list('val')\n",
    "\n",
    "color_mean=(0.485,0.456,0.406)\n",
    "color_std=(0.29,0.224,0.225)\n",
    "\n",
    "transform=dataTransform(475,color_mean,color_std)\n",
    "train_dataset=VOCDataset(train_img_list,train_anno_list,phase=\"train\",transform=transform)\n",
    "val_dataset=VOCDataset(val_img_list,val_anno_list,phase=\"val\",transform=transform)\n",
    "\n",
    "batch_size=4\n",
    "train_dataloader=data.DataLoader(train_dataset,batch_size,True)\n",
    "val_dataloader=data.DataLoader(val_dataset,batch_size,False)\n",
    "\n",
    "dataloaders_dict={\"train\":train_dataloader,\"val\":val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pspnet import PSPNet\n",
    "\n",
    "net=PSPNet(n_classes=150)\n",
    "\n",
    "state_dict=torch.load(\"./weights/pspnet50_ADE20K.pth\") #fine tuning\n",
    "net.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "n_classes=21\n",
    "net.decode_feature.classification=nn.Conv2d(in_channels=512,out_channels=n_classes,kernel_size=1,stride=1,padding=0)\n",
    "net.aux.classification=nn.Conv2d(in_channels=256,out_channels=n_classes,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m,nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias,0.0)\n",
    "\n",
    "net.decode_feature.classification.apply(weights_init)\n",
    "net.aux.classification.apply(weights_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPLoss(nn.Module):\n",
    "    def __init__(self,aux_weight=0.4):\n",
    "        super(PSPLoss,self).__init__()\n",
    "        self.aux_weight=aux_weight\n",
    "    \n",
    "    def forward(self,outputs,targets):\n",
    "        loss=F.cross_entropy(outputs[0],targets,reduction='mean')\n",
    "        loss_aux=F.cross_entropy(outputs[1],targets,reduction='mean')\n",
    "        return loss+self.aux_weight*loss_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=PSPLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD([\n",
    "    {'params':net.feature_conv.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_res_1.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_res_2.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_dilated_res_1.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_dilated_res_2.parameters(),'lr':1e-3},\n",
    "    {'params':net.pyramid_pooling.parameters(),'lr':1e-3},\n",
    "    {'params':net.decode_feature.parameters(),'lr':1e-3},\n",
    "    {'params':net.aux.parameters(),'lr':1e-3},\n",
    "],momentum=0.9,weight_decay=0.0001)\n",
    "\n",
    "def lambda_epoch(epoch):\n",
    "    max_epoch=30\n",
    "    return math.pow((1-epoch/max_epoch),0.9)\n",
    "\n",
    "scheduler=optim.lr_scheduler.LambdaLR(optimizer,lr_lambda=lambda_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net,dataloaders_dict,criterion,scheduler,optimizer,num_epochs):\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    num_train_imgs=len(dataloaders_dict[\"train\"].dataset)\n",
    "    num_val_imgs=len(dataloaders_dict[\"val\"].dataset)\n",
    "    \n",
    "    batch_size=dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    iteration=1\n",
    "    logs=[]\n",
    "\n",
    "    batch_multiplier=3\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        t_epoch_start=time.time()\n",
    "        t_iter_start=time.time()\n",
    "        epoch_train_loss=0.0\n",
    "        epoch_val_loss=0.0\n",
    "\n",
    "        print(f\"{'='*5}Epoch {epoch+1}/{num_epochs}{'='*5}\")\n",
    "        for phase in [\"train\",\"val\"]:\n",
    "            if phase==\"train\":\n",
    "                net.train()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                print(\"[train]\")\n",
    "            else:\n",
    "                if (epoch+1)%5==0:\n",
    "                    net.eval()\n",
    "                    print(\"[val]\")\n",
    "                else: \n",
    "                    continue\n",
    "            count=0\n",
    "            for imgs,anno_class_imgs in dataloaders_dict[phase]:\n",
    "                if imgs.size()[0]==1:\n",
    "                    continue\n",
    "                imgs=imgs.to(device)\n",
    "                anno_class_imgs=anno_class_imgs.to(device)\n",
    "\n",
    "                if phase=='train' and count==0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    count=batch_multiplier\n",
    "                with torch.set_grad_enabled(phase==\"train\"):\n",
    "                    outputs=net(imgs)\n",
    "                    loss=criterion(outputs,anno_class_imgs.long())/batch_multiplier\n",
    "                    if phase==\"train\":\n",
    "                        loss.backward()\n",
    "                        count-=1\n",
    "                        if iteration%10==0:\n",
    "                            t_iter_finish=time.time()\n",
    "                            print(\"iter [{}] loss:{:.4f}   | {:.4f}sec\".format(iteration,loss.item()/batch_size*batch_multiplier,t_iter_finish-t_iter_start))\n",
    "                            t_iter_start=time.time()\n",
    "                        epoch_train_loss+=loss.item()*batch_multiplier\n",
    "                        iteration+=1\n",
    "                    else:\n",
    "                        epoch_val_loss+=loss.item()*batch_multiplier\n",
    "            t_epoch_finish=time.time()\n",
    "            print(\"epoch [{}] train loss:{:.4f}, val loss:{:.4f}  | {:.4f}sec\".format(epoch+1,epoch_train_loss/num_train_imgs,epoch_val_loss/num_val_imgs,t_epoch_finish-t_epoch_start))\n",
    "            t_epoch_start=time.time()\n",
    "\n",
    "            log_epoch={'epoch':epoch+1,'train_loss':epoch_train_loss/num_train_imgs,'val_loss':epoch_val_loss/num_val_imgs}\n",
    "            logs.append(log_epoch)\n",
    "            df=pd.DataFrame(logs)\n",
    "            df.to_csv('log_output.csv')\n",
    "        torch.save(net.state_dict(),'weights/pspnet50_'+str(epoch+1)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "=====Epoch 1/30=====\n",
      "[train]\n",
      "iter [10] loss:1.3323   | 5.9815sec\n",
      "iter [20] loss:1.1108   | 3.1522sec\n",
      "iter [30] loss:0.7835   | 3.1728sec\n",
      "iter [40] loss:0.7306   | 3.1578sec\n",
      "iter [50] loss:0.3389   | 3.2765sec\n",
      "iter [60] loss:0.9328   | 3.4631sec\n",
      "iter [70] loss:0.5702   | 3.3025sec\n",
      "iter [80] loss:0.3518   | 3.2564sec\n",
      "iter [90] loss:0.2815   | 3.1743sec\n",
      "iter [100] loss:0.3610   | 3.1911sec\n",
      "iter [110] loss:0.5245   | 3.2129sec\n",
      "iter [120] loss:0.6376   | 3.2044sec\n",
      "iter [130] loss:0.3975   | 3.1892sec\n",
      "iter [140] loss:0.3770   | 3.0868sec\n",
      "iter [150] loss:0.3989   | 3.1769sec\n",
      "iter [160] loss:0.3410   | 3.0710sec\n",
      "iter [170] loss:0.2409   | 2.9535sec\n",
      "iter [180] loss:0.4378   | 3.0617sec\n",
      "iter [190] loss:0.4378   | 3.1677sec\n",
      "iter [200] loss:0.2121   | 3.0639sec\n",
      "iter [210] loss:0.6483   | 2.9577sec\n",
      "iter [220] loss:0.3859   | 2.9261sec\n",
      "iter [230] loss:0.1193   | 2.9271sec\n",
      "iter [240] loss:0.4662   | 2.9602sec\n",
      "iter [250] loss:0.2357   | 2.9338sec\n",
      "iter [260] loss:0.1840   | 2.9438sec\n",
      "iter [270] loss:0.2228   | 2.9656sec\n",
      "iter [280] loss:0.4101   | 3.0006sec\n",
      "iter [290] loss:0.2087   | 3.0694sec\n",
      "iter [300] loss:0.8464   | 2.9957sec\n",
      "iter [310] loss:0.1685   | 3.0944sec\n",
      "iter [320] loss:0.4852   | 2.9645sec\n",
      "iter [330] loss:0.2937   | 2.9972sec\n",
      "iter [340] loss:0.2601   | 3.0295sec\n",
      "iter [350] loss:0.4015   | 2.9288sec\n",
      "iter [360] loss:0.3581   | 2.9120sec\n",
      "epoch [1] train loss:0.4660, val loss:0.0000  | 124.0989sec\n",
      "=====Epoch 2/30=====\n",
      "[train]\n",
      "iter [370] loss:0.3781   | 1.0628sec\n",
      "iter [380] loss:0.2290   | 2.9391sec\n",
      "iter [390] loss:0.1806   | 2.9571sec\n",
      "iter [400] loss:0.6988   | 2.9139sec\n",
      "iter [410] loss:0.2840   | 2.9236sec\n",
      "iter [420] loss:0.1709   | 2.9157sec\n",
      "iter [430] loss:0.6958   | 3.0040sec\n",
      "iter [440] loss:0.1767   | 2.9587sec\n",
      "iter [450] loss:0.2490   | 2.9247sec\n",
      "iter [460] loss:0.2695   | 2.9338sec\n",
      "iter [470] loss:0.5427   | 2.9345sec\n",
      "iter [480] loss:0.2583   | 2.9577sec\n",
      "iter [490] loss:0.2676   | 2.9533sec\n",
      "iter [500] loss:0.4996   | 2.9420sec\n",
      "iter [510] loss:0.3835   | 2.9945sec\n",
      "iter [520] loss:0.3543   | 2.9460sec\n",
      "iter [530] loss:0.2917   | 2.9377sec\n",
      "iter [540] loss:0.2886   | 3.0410sec\n",
      "iter [550] loss:0.2127   | 3.3039sec\n",
      "iter [560] loss:0.1820   | 2.9601sec\n",
      "iter [570] loss:0.2235   | 3.5317sec\n",
      "iter [580] loss:0.1998   | 3.2880sec\n",
      "iter [590] loss:0.2035   | 3.0703sec\n",
      "iter [600] loss:0.4496   | 3.1718sec\n",
      "iter [610] loss:0.4978   | 3.1761sec\n",
      "iter [620] loss:0.2010   | 3.1114sec\n",
      "iter [630] loss:0.2960   | 3.1715sec\n",
      "iter [640] loss:0.3217   | 3.0333sec\n",
      "iter [650] loss:0.2892   | 3.1241sec\n",
      "iter [660] loss:0.1679   | 3.3031sec\n",
      "iter [670] loss:0.1891   | 3.1682sec\n",
      "iter [680] loss:0.2967   | 2.9742sec\n",
      "iter [690] loss:0.3147   | 3.0218sec\n",
      "iter [700] loss:0.4187   | 3.0180sec\n",
      "iter [710] loss:0.2857   | 3.0895sec\n",
      "iter [720] loss:0.1834   | 3.1930sec\n",
      "iter [730] loss:0.7242   | 3.1452sec\n",
      "epoch [2] train loss:0.3381, val loss:0.0000  | 120.1737sec\n",
      "=====Epoch 3/30=====\n",
      "[train]\n",
      "iter [740] loss:0.4223   | 2.4861sec\n",
      "iter [750] loss:0.1447   | 2.9869sec\n",
      "iter [760] loss:0.2572   | 3.0833sec\n",
      "iter [770] loss:0.3935   | 3.1231sec\n",
      "iter [780] loss:0.2885   | 3.0340sec\n",
      "iter [790] loss:0.2772   | 3.0481sec\n",
      "iter [800] loss:0.1947   | 3.0857sec\n",
      "iter [810] loss:0.4490   | 3.0378sec\n",
      "iter [820] loss:0.3195   | 3.0749sec\n",
      "iter [830] loss:0.3339   | 3.0261sec\n",
      "iter [840] loss:0.2397   | 3.0572sec\n",
      "iter [850] loss:0.2530   | 3.1459sec\n",
      "iter [860] loss:0.2826   | 3.0972sec\n",
      "iter [870] loss:0.4653   | 3.0944sec\n",
      "iter [880] loss:0.3764   | 3.1320sec\n",
      "iter [890] loss:0.2351   | 3.0743sec\n",
      "iter [900] loss:0.1102   | 3.0243sec\n",
      "iter [910] loss:0.2875   | 3.0678sec\n",
      "iter [920] loss:0.4803   | 3.0852sec\n",
      "iter [930] loss:0.3285   | 3.0796sec\n",
      "iter [940] loss:0.3315   | 2.9339sec\n",
      "iter [950] loss:0.2317   | 2.9259sec\n",
      "iter [960] loss:0.1842   | 2.9157sec\n",
      "iter [970] loss:0.6328   | 2.9433sec\n",
      "iter [980] loss:0.3953   | 3.0590sec\n",
      "iter [990] loss:0.1848   | 2.9576sec\n",
      "iter [1000] loss:0.3273   | 2.9865sec\n",
      "iter [1010] loss:0.2434   | 3.0860sec\n",
      "iter [1020] loss:0.1777   | 3.0942sec\n",
      "iter [1030] loss:0.3232   | 3.3682sec\n",
      "iter [1040] loss:0.2990   | 3.2718sec\n",
      "iter [1050] loss:0.4944   | 3.1334sec\n",
      "iter [1060] loss:0.2662   | 3.0096sec\n",
      "iter [1070] loss:0.1443   | 3.2570sec\n",
      "iter [1080] loss:0.2121   | 3.1857sec\n",
      "iter [1090] loss:0.2197   | 3.2395sec\n",
      "epoch [3] train loss:0.3213, val loss:0.0000  | 121.0487sec\n",
      "=====Epoch 4/30=====\n",
      "[train]\n",
      "iter [1100] loss:0.3382   | 0.4152sec\n",
      "iter [1110] loss:0.3491   | 2.9551sec\n",
      "iter [1120] loss:0.1616   | 3.0499sec\n",
      "iter [1130] loss:0.2067   | 3.0096sec\n",
      "iter [1140] loss:0.4191   | 2.9929sec\n",
      "iter [1150] loss:0.3828   | 2.9914sec\n",
      "iter [1160] loss:0.3106   | 3.2343sec\n",
      "iter [1170] loss:0.2294   | 3.0002sec\n",
      "iter [1180] loss:0.2889   | 2.9807sec\n",
      "iter [1190] loss:0.4064   | 3.0165sec\n",
      "iter [1200] loss:0.4784   | 3.0158sec\n",
      "iter [1210] loss:0.3356   | 3.0437sec\n",
      "iter [1220] loss:0.2710   | 2.9452sec\n",
      "iter [1230] loss:0.2234   | 3.0813sec\n",
      "iter [1240] loss:0.2962   | 3.0500sec\n",
      "iter [1250] loss:0.3918   | 2.9254sec\n",
      "iter [1260] loss:0.2135   | 2.9548sec\n",
      "iter [1270] loss:0.4086   | 2.9923sec\n",
      "iter [1280] loss:0.3578   | 3.0851sec\n",
      "iter [1290] loss:0.2636   | 3.0887sec\n",
      "iter [1300] loss:0.3052   | 3.0474sec\n",
      "iter [1310] loss:0.3283   | 3.0292sec\n",
      "iter [1320] loss:0.3874   | 2.9336sec\n",
      "iter [1330] loss:0.1684   | 3.0954sec\n",
      "iter [1340] loss:0.2711   | 3.0166sec\n",
      "iter [1350] loss:0.2869   | 2.9875sec\n",
      "iter [1360] loss:0.2499   | 2.9919sec\n",
      "iter [1370] loss:0.2735   | 3.0479sec\n",
      "iter [1380] loss:0.3647   | 3.0038sec\n",
      "iter [1390] loss:0.2173   | 3.0621sec\n",
      "iter [1400] loss:0.1414   | 3.0413sec\n",
      "iter [1410] loss:0.4238   | 2.9913sec\n",
      "iter [1420] loss:0.3249   | 2.9420sec\n",
      "iter [1430] loss:0.1481   | 3.0622sec\n",
      "iter [1440] loss:0.3424   | 3.0576sec\n",
      "iter [1450] loss:0.2489   | 3.0935sec\n",
      "iter [1460] loss:0.1578   | 3.0029sec\n",
      "epoch [4] train loss:0.3089, val loss:0.0000  | 119.0146sec\n",
      "=====Epoch 5/30=====\n",
      "[train]\n",
      "iter [1470] loss:0.1822   | 1.7467sec\n",
      "iter [1480] loss:0.3095   | 3.0952sec\n",
      "iter [1490] loss:0.4398   | 2.9812sec\n",
      "iter [1500] loss:0.8127   | 3.0368sec\n",
      "iter [1510] loss:0.2411   | 3.0877sec\n",
      "iter [1520] loss:0.4149   | 2.9654sec\n",
      "iter [1530] loss:0.4064   | 2.9813sec\n",
      "iter [1540] loss:0.2130   | 3.1092sec\n",
      "iter [1550] loss:0.3159   | 3.0741sec\n",
      "iter [1560] loss:0.3508   | 3.0512sec\n",
      "iter [1570] loss:0.3050   | 3.1538sec\n",
      "iter [1580] loss:0.2365   | 3.1312sec\n",
      "iter [1590] loss:0.1654   | 3.1707sec\n",
      "iter [1600] loss:0.2719   | 3.2563sec\n",
      "iter [1610] loss:0.4913   | 3.0539sec\n",
      "iter [1620] loss:0.3657   | 2.9122sec\n",
      "iter [1630] loss:0.2726   | 3.0464sec\n",
      "iter [1640] loss:0.5385   | 2.9539sec\n",
      "iter [1650] loss:0.4889   | 2.9726sec\n",
      "iter [1660] loss:0.2997   | 2.9691sec\n",
      "iter [1670] loss:0.1550   | 2.9648sec\n",
      "iter [1680] loss:0.2554   | 2.9649sec\n",
      "iter [1690] loss:0.4011   | 3.0044sec\n",
      "iter [1700] loss:0.3294   | 3.1846sec\n",
      "iter [1710] loss:0.1855   | 3.3427sec\n",
      "iter [1720] loss:0.1919   | 3.3726sec\n",
      "iter [1730] loss:0.2276   | 3.2424sec\n",
      "iter [1740] loss:0.4218   | 3.0970sec\n",
      "iter [1750] loss:0.2886   | 2.9942sec\n",
      "iter [1760] loss:0.2219   | 3.0800sec\n",
      "iter [1770] loss:0.1855   | 2.9335sec\n",
      "iter [1780] loss:0.2286   | 3.0324sec\n",
      "iter [1790] loss:0.2781   | 3.1908sec\n",
      "iter [1800] loss:0.3414   | 3.1603sec\n",
      "iter [1810] loss:0.1680   | 3.0284sec\n",
      "iter [1820] loss:0.1598   | 2.9748sec\n",
      "iter [1830] loss:0.2970   | 2.9449sec\n",
      "epoch [5] train loss:0.2972, val loss:0.0000  | 120.7160sec\n",
      "[val]\n",
      "epoch [5] train loss:0.2972, val loss:0.3093  | 39.8346sec\n",
      "=====Epoch 6/30=====\n",
      "[train]\n",
      "iter [1840] loss:0.5862   | 2.9556sec\n",
      "iter [1850] loss:0.5189   | 3.1177sec\n",
      "iter [1860] loss:0.3980   | 2.9560sec\n",
      "iter [1870] loss:0.2839   | 3.0099sec\n",
      "iter [1880] loss:0.3175   | 3.2727sec\n",
      "iter [1890] loss:0.1343   | 2.9492sec\n",
      "iter [1900] loss:0.1243   | 2.9987sec\n",
      "iter [1910] loss:0.1335   | 3.0568sec\n",
      "iter [1920] loss:0.2602   | 3.1165sec\n",
      "iter [1930] loss:0.2628   | 2.9402sec\n",
      "iter [1940] loss:0.2831   | 3.0119sec\n",
      "iter [1950] loss:0.2607   | 2.9372sec\n",
      "iter [1960] loss:0.2701   | 2.9216sec\n",
      "iter [1970] loss:0.1808   | 2.9201sec\n",
      "iter [1980] loss:0.3162   | 2.9149sec\n",
      "iter [1990] loss:0.2269   | 2.9736sec\n",
      "iter [2000] loss:0.1701   | 2.9958sec\n",
      "iter [2010] loss:0.1935   | 2.9377sec\n",
      "iter [2020] loss:0.2003   | 2.9628sec\n",
      "iter [2030] loss:0.3001   | 2.9506sec\n",
      "iter [2040] loss:0.1731   | 2.9811sec\n",
      "iter [2050] loss:0.1149   | 3.1091sec\n",
      "iter [2060] loss:0.1802   | 3.1614sec\n",
      "iter [2070] loss:0.1996   | 3.1396sec\n",
      "iter [2080] loss:0.3192   | 3.1211sec\n",
      "iter [2090] loss:0.1680   | 3.0984sec\n",
      "iter [2100] loss:0.3238   | 3.1559sec\n",
      "iter [2110] loss:0.1230   | 3.0160sec\n",
      "iter [2120] loss:0.2017   | 3.0471sec\n",
      "iter [2130] loss:0.1900   | 3.0618sec\n",
      "iter [2140] loss:0.2542   | 3.0543sec\n",
      "iter [2150] loss:0.2793   | 3.0455sec\n",
      "iter [2160] loss:0.2795   | 3.1270sec\n",
      "iter [2170] loss:0.2539   | 3.2481sec\n",
      "iter [2180] loss:0.2472   | 3.0235sec\n",
      "iter [2190] loss:0.4527   | 2.9291sec\n",
      "epoch [6] train loss:0.2974, val loss:0.0000  | 119.2624sec\n",
      "=====Epoch 7/30=====\n",
      "[train]\n",
      "iter [2200] loss:0.2147   | 1.0485sec\n",
      "iter [2210] loss:0.1415   | 2.9417sec\n",
      "iter [2220] loss:0.1536   | 2.9360sec\n",
      "iter [2230] loss:0.4994   | 2.9239sec\n",
      "iter [2240] loss:0.1704   | 2.9549sec\n",
      "iter [2250] loss:0.1609   | 2.9187sec\n",
      "iter [2260] loss:0.2877   | 2.9902sec\n",
      "iter [2270] loss:0.2774   | 3.0952sec\n",
      "iter [2280] loss:0.2742   | 3.1233sec\n",
      "iter [2290] loss:0.3233   | 3.1557sec\n",
      "iter [2300] loss:0.4386   | 3.0419sec\n",
      "iter [2310] loss:0.1704   | 3.0554sec\n",
      "iter [2320] loss:0.1873   | 2.9580sec\n",
      "iter [2330] loss:0.2123   | 2.9732sec\n",
      "iter [2340] loss:0.2808   | 2.9336sec\n",
      "iter [2350] loss:0.2975   | 2.9506sec\n",
      "iter [2360] loss:0.1594   | 2.9676sec\n",
      "iter [2370] loss:0.3377   | 2.9495sec\n",
      "iter [2380] loss:0.1396   | 3.0911sec\n",
      "iter [2390] loss:0.7770   | 2.9976sec\n",
      "iter [2400] loss:0.1626   | 3.0242sec\n",
      "iter [2410] loss:0.2633   | 3.0033sec\n",
      "iter [2420] loss:0.1958   | 2.9408sec\n",
      "iter [2430] loss:0.2510   | 2.9234sec\n",
      "iter [2440] loss:0.1836   | 2.9282sec\n",
      "iter [2450] loss:0.3511   | 2.9621sec\n",
      "iter [2460] loss:0.1747   | 2.9407sec\n",
      "iter [2470] loss:0.1449   | 2.9288sec\n",
      "iter [2480] loss:0.4694   | 2.9494sec\n",
      "iter [2490] loss:0.3109   | 2.9398sec\n",
      "iter [2500] loss:0.2524   | 2.9516sec\n",
      "iter [2510] loss:0.1980   | 2.9297sec\n",
      "iter [2520] loss:0.3033   | 2.9379sec\n",
      "iter [2530] loss:0.2520   | 2.9536sec\n",
      "iter [2540] loss:0.3023   | 2.9418sec\n",
      "iter [2550] loss:0.2516   | 2.9389sec\n",
      "iter [2560] loss:0.2304   | 2.9369sec\n",
      "epoch [7] train loss:0.2857, val loss:0.0000  | 117.0920sec\n",
      "=====Epoch 8/30=====\n",
      "[train]\n",
      "iter [2570] loss:0.4792   | 2.3164sec\n",
      "iter [2580] loss:0.5018   | 2.9088sec\n",
      "iter [2590] loss:0.3546   | 2.9512sec\n",
      "iter [2600] loss:0.2379   | 2.9291sec\n",
      "iter [2610] loss:0.5857   | 3.0663sec\n",
      "iter [2620] loss:0.1299   | 2.9422sec\n",
      "iter [2630] loss:0.2370   | 3.0438sec\n",
      "iter [2640] loss:0.3371   | 3.0353sec\n",
      "iter [2650] loss:0.3392   | 3.2387sec\n",
      "iter [2660] loss:0.3029   | 3.1196sec\n",
      "iter [2670] loss:0.3867   | 3.1425sec\n",
      "iter [2680] loss:0.1594   | 3.1289sec\n",
      "iter [2690] loss:0.1386   | 3.0062sec\n",
      "iter [2700] loss:0.3032   | 3.0491sec\n",
      "iter [2710] loss:0.1987   | 3.0807sec\n",
      "iter [2720] loss:0.1559   | 3.0229sec\n",
      "iter [2730] loss:0.1808   | 2.9755sec\n",
      "iter [2740] loss:0.4233   | 2.9062sec\n",
      "iter [2750] loss:0.4269   | 3.1374sec\n",
      "iter [2760] loss:0.2654   | 3.1032sec\n",
      "iter [2770] loss:0.1460   | 2.9879sec\n",
      "iter [2780] loss:0.1183   | 2.9922sec\n",
      "iter [2790] loss:0.3595   | 3.0695sec\n",
      "iter [2800] loss:0.5406   | 3.0279sec\n",
      "iter [2810] loss:0.3246   | 2.9676sec\n",
      "iter [2820] loss:0.3185   | 3.0064sec\n",
      "iter [2830] loss:0.1441   | 2.9820sec\n",
      "iter [2840] loss:0.1871   | 3.0708sec\n",
      "iter [2850] loss:0.3886   | 3.0433sec\n",
      "iter [2860] loss:0.2112   | 3.0637sec\n",
      "iter [2870] loss:0.2326   | 2.9793sec\n",
      "iter [2880] loss:0.4124   | 3.0330sec\n",
      "iter [2890] loss:0.3274   | 3.1281sec\n",
      "iter [2900] loss:0.2210   | 3.0388sec\n",
      "iter [2910] loss:0.3548   | 3.0125sec\n",
      "iter [2920] loss:0.1901   | 3.1241sec\n",
      "epoch [8] train loss:0.2742, val loss:0.0000  | 119.4093sec\n",
      "=====Epoch 9/30=====\n",
      "[train]\n",
      "iter [2930] loss:0.4226   | 0.4110sec\n",
      "iter [2940] loss:0.3893   | 3.0080sec\n",
      "iter [2950] loss:0.2571   | 3.0906sec\n",
      "iter [2960] loss:0.1972   | 3.0647sec\n",
      "iter [2970] loss:0.1816   | 3.0204sec\n",
      "iter [2980] loss:0.5204   | 2.9818sec\n",
      "iter [2990] loss:0.2429   | 2.9404sec\n",
      "iter [3000] loss:0.3081   | 3.0048sec\n",
      "iter [3010] loss:0.2123   | 2.9740sec\n",
      "iter [3020] loss:0.5271   | 2.9708sec\n",
      "iter [3030] loss:0.1593   | 2.9383sec\n",
      "iter [3040] loss:0.2638   | 2.9760sec\n",
      "iter [3050] loss:0.1739   | 2.9182sec\n",
      "iter [3060] loss:0.2679   | 3.0079sec\n",
      "iter [3070] loss:0.2167   | 3.2109sec\n",
      "iter [3080] loss:0.2185   | 3.1311sec\n",
      "iter [3090] loss:0.3137   | 3.0021sec\n",
      "iter [3100] loss:0.3484   | 2.9943sec\n",
      "iter [3110] loss:0.4303   | 2.9728sec\n",
      "iter [3120] loss:0.1124   | 2.9574sec\n",
      "iter [3130] loss:0.1496   | 2.9526sec\n",
      "iter [3140] loss:0.2457   | 2.9869sec\n",
      "iter [3150] loss:0.7800   | 3.1172sec\n",
      "iter [3160] loss:0.3261   | 3.1693sec\n",
      "iter [3170] loss:0.2975   | 3.1305sec\n",
      "iter [3180] loss:0.1969   | 3.0988sec\n",
      "iter [3190] loss:0.1248   | 3.0525sec\n",
      "iter [3200] loss:0.2820   | 3.0000sec\n",
      "iter [3210] loss:0.5465   | 3.0281sec\n",
      "iter [3220] loss:0.1593   | 3.0025sec\n",
      "iter [3230] loss:0.2042   | 2.9452sec\n",
      "iter [3240] loss:0.3593   | 3.2108sec\n",
      "iter [3250] loss:0.2501   | 3.4107sec\n",
      "iter [3260] loss:0.1991   | 3.2361sec\n",
      "iter [3270] loss:0.2373   | 3.3001sec\n",
      "iter [3280] loss:0.2051   | 3.1702sec\n",
      "iter [3290] loss:0.2662   | 3.2643sec\n",
      "epoch [9] train loss:0.2871, val loss:0.0000  | 120.5581sec\n",
      "=====Epoch 10/30=====\n",
      "[train]\n",
      "iter [3300] loss:0.3324   | 1.9313sec\n",
      "iter [3310] loss:0.1726   | 3.2861sec\n",
      "iter [3320] loss:0.1753   | 3.2611sec\n",
      "iter [3330] loss:0.3709   | 3.2205sec\n",
      "iter [3340] loss:0.2389   | 3.1652sec\n",
      "iter [3350] loss:0.2221   | 3.1792sec\n",
      "iter [3360] loss:0.2718   | 3.1730sec\n",
      "iter [3370] loss:0.2040   | 3.1537sec\n",
      "iter [3380] loss:0.1859   | 3.2054sec\n",
      "iter [3390] loss:0.4172   | 3.1708sec\n",
      "iter [3400] loss:0.2969   | 3.1875sec\n",
      "iter [3410] loss:0.3035   | 3.1435sec\n",
      "iter [3420] loss:0.1677   | 3.1690sec\n",
      "iter [3430] loss:0.1872   | 3.1678sec\n",
      "iter [3440] loss:0.2038   | 3.1565sec\n",
      "iter [3450] loss:0.0958   | 3.1521sec\n",
      "iter [3460] loss:0.3892   | 3.1629sec\n",
      "iter [3470] loss:0.3097   | 3.1528sec\n",
      "iter [3480] loss:0.2283   | 3.1864sec\n",
      "iter [3490] loss:0.2775   | 3.1857sec\n",
      "iter [3500] loss:0.1406   | 3.2338sec\n",
      "iter [3510] loss:0.2965   | 3.1529sec\n",
      "iter [3520] loss:0.3846   | 3.1729sec\n",
      "iter [3530] loss:0.4429   | 3.1793sec\n",
      "iter [3540] loss:0.1809   | 3.1672sec\n",
      "iter [3550] loss:0.1569   | 3.1641sec\n",
      "iter [3560] loss:0.4705   | 3.1741sec\n",
      "iter [3570] loss:0.3976   | 3.1679sec\n",
      "iter [3580] loss:0.2068   | 3.1594sec\n",
      "iter [3590] loss:0.3235   | 3.1216sec\n",
      "iter [3600] loss:0.1218   | 3.1571sec\n",
      "iter [3610] loss:0.2859   | 3.2093sec\n",
      "iter [3620] loss:0.3749   | 3.1297sec\n",
      "iter [3630] loss:0.0897   | 3.1417sec\n",
      "iter [3640] loss:0.2744   | 3.1898sec\n",
      "iter [3650] loss:0.1640   | 3.1566sec\n",
      "iter [3660] loss:0.1890   | 3.1206sec\n",
      "epoch [10] train loss:0.2673, val loss:0.0000  | 125.1520sec\n",
      "[val]\n",
      "epoch [10] train loss:0.2673, val loss:0.2916  | 40.3883sec\n",
      "=====Epoch 11/30=====\n",
      "[train]\n",
      "iter [3670] loss:0.1430   | 3.2156sec\n",
      "iter [3680] loss:0.2928   | 3.1576sec\n",
      "iter [3690] loss:0.1717   | 3.1522sec\n",
      "iter [3700] loss:0.1518   | 3.1818sec\n",
      "iter [3710] loss:0.3550   | 3.1690sec\n",
      "iter [3720] loss:0.3667   | 3.1677sec\n",
      "iter [3730] loss:0.4164   | 3.1699sec\n",
      "iter [3740] loss:0.0887   | 3.1520sec\n",
      "iter [3750] loss:0.1442   | 3.1836sec\n",
      "iter [3760] loss:0.1524   | 3.1557sec\n",
      "iter [3770] loss:0.2834   | 3.1481sec\n",
      "iter [3780] loss:0.4017   | 3.1627sec\n",
      "iter [3790] loss:0.2574   | 3.1863sec\n",
      "iter [3800] loss:0.1316   | 3.1845sec\n",
      "iter [3810] loss:0.1884   | 3.1710sec\n",
      "iter [3820] loss:0.1919   | 3.1833sec\n",
      "iter [3830] loss:0.2351   | 3.1543sec\n",
      "iter [3840] loss:0.1702   | 3.1723sec\n",
      "iter [3850] loss:0.2508   | 3.1836sec\n",
      "iter [3860] loss:0.2491   | 3.1580sec\n",
      "iter [3870] loss:0.3237   | 3.1731sec\n",
      "iter [3880] loss:0.3020   | 3.1620sec\n",
      "iter [3890] loss:0.1579   | 3.1713sec\n",
      "iter [3900] loss:0.2667   | 3.1475sec\n",
      "iter [3910] loss:0.1897   | 3.1607sec\n",
      "iter [3920] loss:0.2841   | 3.1752sec\n",
      "iter [3930] loss:0.1631   | 3.1492sec\n",
      "iter [3940] loss:0.6754   | 3.1733sec\n",
      "iter [3950] loss:1.0038   | 3.1591sec\n",
      "iter [3960] loss:0.1682   | 3.1634sec\n",
      "iter [3970] loss:0.2267   | 3.1282sec\n",
      "iter [3980] loss:0.3216   | 3.1461sec\n",
      "iter [3990] loss:0.1480   | 3.1528sec\n",
      "iter [4000] loss:0.4413   | 3.1591sec\n",
      "iter [4010] loss:0.1706   | 3.1874sec\n",
      "iter [4020] loss:0.1768   | 3.1770sec\n",
      "epoch [11] train loss:0.2735, val loss:0.0000  | 124.8069sec\n",
      "=====Epoch 12/30=====\n",
      "[train]\n",
      "iter [4030] loss:0.3710   | 1.0962sec\n",
      "iter [4040] loss:0.1450   | 3.1996sec\n",
      "iter [4050] loss:0.1063   | 3.4125sec\n",
      "iter [4060] loss:0.2945   | 3.0327sec\n",
      "iter [4070] loss:0.2145   | 3.1588sec\n",
      "iter [4080] loss:0.1334   | 3.3296sec\n",
      "iter [4090] loss:0.1286   | 3.5825sec\n",
      "iter [4100] loss:0.1683   | 3.2774sec\n",
      "iter [4110] loss:0.3839   | 3.0886sec\n",
      "iter [4120] loss:0.2250   | 3.0507sec\n",
      "iter [4130] loss:0.1814   | 3.2000sec\n",
      "iter [4140] loss:0.3149   | 3.1122sec\n",
      "iter [4150] loss:0.4166   | 3.1465sec\n",
      "iter [4160] loss:0.3413   | 3.0582sec\n",
      "iter [4170] loss:0.2988   | 3.2196sec\n",
      "iter [4180] loss:0.2728   | 3.5150sec\n",
      "iter [4190] loss:0.1425   | 3.1903sec\n",
      "iter [4200] loss:0.2669   | 3.0319sec\n",
      "iter [4210] loss:0.5090   | 3.0373sec\n",
      "iter [4220] loss:0.2530   | 3.0149sec\n",
      "iter [4230] loss:0.4077   | 3.1047sec\n",
      "iter [4240] loss:0.1890   | 3.1733sec\n",
      "iter [4250] loss:0.1594   | 3.0169sec\n",
      "iter [4260] loss:0.1809   | 3.0812sec\n",
      "iter [4270] loss:0.3491   | 3.0036sec\n",
      "iter [4280] loss:0.3117   | 2.9614sec\n",
      "iter [4290] loss:0.2020   | 3.0053sec\n",
      "iter [4300] loss:0.3413   | 2.9380sec\n",
      "iter [4310] loss:0.5160   | 2.9996sec\n",
      "iter [4320] loss:0.1856   | 2.9557sec\n",
      "iter [4330] loss:0.1974   | 3.1456sec\n",
      "iter [4340] loss:0.1597   | 3.0989sec\n",
      "iter [4350] loss:0.3589   | 3.0785sec\n",
      "iter [4360] loss:0.2667   | 3.1642sec\n",
      "iter [4370] loss:0.6132   | 3.1283sec\n",
      "iter [4380] loss:0.2135   | 3.0856sec\n",
      "iter [4390] loss:0.1975   | 3.1122sec\n",
      "epoch [12] train loss:0.2581, val loss:0.0000  | 122.8334sec\n",
      "=====Epoch 13/30=====\n",
      "[train]\n",
      "iter [4400] loss:0.1992   | 2.4270sec\n",
      "iter [4410] loss:0.3985   | 3.1613sec\n",
      "iter [4420] loss:0.1832   | 3.1367sec\n",
      "iter [4430] loss:0.3901   | 3.0014sec\n",
      "iter [4440] loss:0.1741   | 3.0791sec\n",
      "iter [4450] loss:0.1718   | 3.0185sec\n",
      "iter [4460] loss:0.2911   | 2.9868sec\n",
      "iter [4470] loss:0.1655   | 3.0529sec\n",
      "iter [4480] loss:0.2326   | 3.0886sec\n",
      "iter [4490] loss:0.1536   | 3.1795sec\n",
      "iter [4500] loss:0.4154   | 3.0115sec\n",
      "iter [4510] loss:0.1446   | 3.0947sec\n",
      "iter [4520] loss:0.3096   | 3.1899sec\n",
      "iter [4530] loss:0.2547   | 3.3371sec\n",
      "iter [4540] loss:0.1998   | 3.1364sec\n",
      "iter [4550] loss:0.1683   | 3.1611sec\n",
      "iter [4560] loss:0.2154   | 3.3011sec\n",
      "iter [4570] loss:0.3218   | 3.0837sec\n",
      "iter [4580] loss:0.1255   | 3.2404sec\n",
      "iter [4590] loss:0.2094   | 3.2191sec\n",
      "iter [4600] loss:0.3000   | 3.2404sec\n",
      "iter [4610] loss:0.4296   | 3.3334sec\n",
      "iter [4620] loss:0.3056   | 3.3071sec\n",
      "iter [4630] loss:0.2263   | 3.2492sec\n",
      "iter [4640] loss:0.2698   | 3.3467sec\n",
      "iter [4650] loss:0.3170   | 3.1667sec\n",
      "iter [4660] loss:0.2338   | 3.2094sec\n",
      "iter [4670] loss:0.0801   | 3.1746sec\n",
      "iter [4680] loss:0.2776   | 3.1844sec\n",
      "iter [4690] loss:0.1920   | 3.1770sec\n",
      "iter [4700] loss:0.3597   | 3.2021sec\n",
      "iter [4710] loss:0.2505   | 3.1883sec\n",
      "iter [4720] loss:0.3034   | 3.2066sec\n",
      "iter [4730] loss:0.2438   | 3.1903sec\n",
      "iter [4740] loss:0.1227   | 3.1659sec\n",
      "iter [4750] loss:0.1425   | 3.0357sec\n",
      "epoch [13] train loss:0.2532, val loss:0.0000  | 124.4017sec\n",
      "=====Epoch 14/30=====\n",
      "[train]\n",
      "iter [4760] loss:0.2711   | 0.4491sec\n",
      "iter [4770] loss:0.3078   | 3.0194sec\n",
      "iter [4780] loss:0.1686   | 3.0293sec\n",
      "iter [4790] loss:0.1598   | 2.9840sec\n",
      "iter [4800] loss:0.4778   | 3.0136sec\n",
      "iter [4810] loss:0.1603   | 2.9863sec\n",
      "iter [4820] loss:0.0993   | 3.0194sec\n",
      "iter [4830] loss:0.2035   | 3.0016sec\n",
      "iter [4840] loss:0.3495   | 3.0276sec\n",
      "iter [4850] loss:0.3581   | 2.9910sec\n",
      "iter [4860] loss:0.3672   | 3.0001sec\n",
      "iter [4870] loss:0.2604   | 3.0056sec\n",
      "iter [4880] loss:0.1754   | 3.0054sec\n",
      "iter [4890] loss:0.5041   | 2.9958sec\n",
      "iter [4900] loss:0.1287   | 3.0130sec\n",
      "iter [4910] loss:0.1637   | 2.9907sec\n",
      "iter [4920] loss:0.1677   | 2.9983sec\n",
      "iter [4930] loss:0.3027   | 2.9958sec\n",
      "iter [4940] loss:0.2058   | 3.0149sec\n",
      "iter [4950] loss:0.3148   | 3.0176sec\n",
      "iter [4960] loss:0.2484   | 2.9979sec\n",
      "iter [4970] loss:0.2616   | 3.0128sec\n",
      "iter [4980] loss:0.2602   | 2.9924sec\n",
      "iter [4990] loss:0.5107   | 2.9949sec\n",
      "iter [5000] loss:0.0882   | 3.0039sec\n",
      "iter [5010] loss:0.2657   | 3.0075sec\n",
      "iter [5020] loss:0.2724   | 3.0039sec\n",
      "iter [5030] loss:0.3148   | 3.0201sec\n",
      "iter [5040] loss:0.1652   | 2.9998sec\n",
      "iter [5050] loss:0.2691   | 2.9969sec\n",
      "iter [5060] loss:0.2389   | 2.9997sec\n",
      "iter [5070] loss:0.1278   | 2.9948sec\n",
      "iter [5080] loss:0.1974   | 2.9818sec\n",
      "iter [5090] loss:0.2126   | 3.0242sec\n",
      "iter [5100] loss:0.1237   | 2.9887sec\n",
      "iter [5110] loss:0.3073   | 3.0219sec\n",
      "iter [5120] loss:0.2152   | 3.0031sec\n",
      "epoch [14] train loss:0.2495, val loss:0.0000  | 118.0893sec\n",
      "=====Epoch 15/30=====\n",
      "[train]\n",
      "iter [5130] loss:0.1524   | 1.8115sec\n",
      "iter [5140] loss:0.1632   | 2.9965sec\n",
      "iter [5150] loss:0.1352   | 3.0221sec\n",
      "iter [5160] loss:0.2147   | 2.9998sec\n",
      "iter [5170] loss:0.2094   | 3.0167sec\n",
      "iter [5180] loss:0.1346   | 3.0030sec\n",
      "iter [5190] loss:0.7627   | 3.0003sec\n",
      "iter [5200] loss:0.2798   | 3.0294sec\n",
      "iter [5210] loss:0.1968   | 2.9969sec\n",
      "iter [5220] loss:0.1498   | 2.9908sec\n",
      "iter [5230] loss:0.2274   | 2.9911sec\n",
      "iter [5240] loss:0.4978   | 3.0276sec\n",
      "iter [5250] loss:0.2231   | 3.0017sec\n",
      "iter [5260] loss:0.3351   | 3.0252sec\n",
      "iter [5270] loss:0.1686   | 3.0091sec\n",
      "iter [5280] loss:0.5101   | 2.9983sec\n",
      "iter [5290] loss:0.1392   | 2.9904sec\n",
      "iter [5300] loss:0.1326   | 3.0280sec\n",
      "iter [5310] loss:0.1704   | 3.0165sec\n",
      "iter [5320] loss:0.1384   | 3.0098sec\n",
      "iter [5330] loss:0.2871   | 3.0226sec\n",
      "iter [5340] loss:0.1655   | 3.0083sec\n",
      "iter [5350] loss:0.2490   | 3.0285sec\n",
      "iter [5360] loss:0.1745   | 3.0079sec\n",
      "iter [5370] loss:0.3415   | 3.0076sec\n",
      "iter [5380] loss:0.5017   | 3.0190sec\n",
      "iter [5390] loss:0.3259   | 2.9894sec\n",
      "iter [5400] loss:0.4144   | 2.9943sec\n",
      "iter [5410] loss:0.1375   | 3.0178sec\n",
      "iter [5420] loss:0.2374   | 2.9993sec\n",
      "iter [5430] loss:0.6876   | 3.0098sec\n",
      "iter [5440] loss:0.2006   | 3.0053sec\n",
      "iter [5450] loss:0.3370   | 2.9959sec\n",
      "iter [5460] loss:0.1259   | 3.0202sec\n",
      "iter [5470] loss:0.3330   | 3.0295sec\n",
      "iter [5480] loss:0.1624   | 3.0074sec\n",
      "iter [5490] loss:0.2604   | 3.0151sec\n",
      "epoch [15] train loss:0.2536, val loss:0.0000  | 118.3108sec\n",
      "[val]\n",
      "epoch [15] train loss:0.2536, val loss:0.2874  | 38.0595sec\n",
      "=====Epoch 16/30=====\n",
      "[train]\n",
      "iter [5500] loss:0.6049   | 3.0844sec\n",
      "iter [5510] loss:0.2085   | 3.0001sec\n",
      "iter [5520] loss:0.2096   | 3.0199sec\n",
      "iter [5530] loss:0.2491   | 3.0149sec\n",
      "iter [5540] loss:0.3290   | 3.0187sec\n",
      "iter [5550] loss:0.3396   | 3.0305sec\n",
      "iter [5560] loss:0.2054   | 3.0066sec\n",
      "iter [5570] loss:0.1814   | 3.0072sec\n",
      "iter [5580] loss:0.2048   | 3.0088sec\n",
      "iter [5590] loss:0.1625   | 3.0019sec\n",
      "iter [5600] loss:0.1911   | 2.9818sec\n",
      "iter [5610] loss:0.2779   | 3.0187sec\n",
      "iter [5620] loss:0.1939   | 2.9966sec\n",
      "iter [5630] loss:0.2831   | 2.9992sec\n",
      "iter [5640] loss:0.2677   | 2.9951sec\n",
      "iter [5650] loss:0.1144   | 3.0019sec\n",
      "iter [5660] loss:0.1214   | 3.0134sec\n",
      "iter [5670] loss:0.3348   | 2.9917sec\n",
      "iter [5680] loss:0.2968   | 3.0233sec\n",
      "iter [5690] loss:0.2343   | 2.9907sec\n",
      "iter [5700] loss:0.4007   | 3.0226sec\n",
      "iter [5710] loss:0.1718   | 3.0332sec\n",
      "iter [5720] loss:0.2769   | 2.9864sec\n",
      "iter [5730] loss:0.1405   | 3.0129sec\n",
      "iter [5740] loss:0.2455   | 3.0029sec\n",
      "iter [5750] loss:0.2538   | 3.0309sec\n",
      "iter [5760] loss:0.2682   | 2.9945sec\n",
      "iter [5770] loss:0.1247   | 3.0202sec\n",
      "iter [5780] loss:0.2374   | 3.0695sec\n",
      "iter [5790] loss:0.2301   | 3.0006sec\n",
      "iter [5800] loss:0.2434   | 3.0175sec\n",
      "iter [5810] loss:0.2410   | 3.0181sec\n",
      "iter [5820] loss:0.2839   | 3.0020sec\n",
      "iter [5830] loss:0.1360   | 3.0145sec\n",
      "iter [5840] loss:0.1703   | 2.9924sec\n",
      "iter [5850] loss:0.3899   | 3.0114sec\n",
      "epoch [16] train loss:0.2454, val loss:0.0000  | 118.3639sec\n",
      "=====Epoch 17/30=====\n",
      "[train]\n",
      "iter [5860] loss:0.2121   | 1.1319sec\n",
      "iter [5870] loss:0.3269   | 3.0206sec\n",
      "iter [5880] loss:0.3392   | 2.9991sec\n",
      "iter [5890] loss:0.1298   | 3.0153sec\n",
      "iter [5900] loss:0.4699   | 2.9918sec\n",
      "iter [5910] loss:0.3498   | 2.9900sec\n",
      "iter [5920] loss:0.1781   | 2.9888sec\n",
      "iter [5930] loss:0.1406   | 3.0129sec\n",
      "iter [5940] loss:0.1521   | 3.0079sec\n",
      "iter [5950] loss:0.2658   | 2.9986sec\n",
      "iter [5960] loss:0.2952   | 2.9970sec\n",
      "iter [5970] loss:0.1730   | 2.9922sec\n",
      "iter [5980] loss:0.3646   | 3.0091sec\n",
      "iter [5990] loss:0.2700   | 3.0149sec\n",
      "iter [6000] loss:0.2449   | 3.0127sec\n",
      "iter [6010] loss:0.1303   | 3.0156sec\n",
      "iter [6020] loss:0.2012   | 2.9976sec\n",
      "iter [6030] loss:0.1935   | 3.0122sec\n",
      "iter [6040] loss:0.1256   | 3.0138sec\n",
      "iter [6050] loss:0.3294   | 3.0038sec\n",
      "iter [6060] loss:0.3715   | 2.9894sec\n",
      "iter [6070] loss:0.2470   | 3.0221sec\n",
      "iter [6080] loss:0.1855   | 3.0181sec\n",
      "iter [6090] loss:0.2950   | 3.0617sec\n",
      "iter [6100] loss:0.5628   | 3.0189sec\n",
      "iter [6110] loss:0.3333   | 3.0034sec\n",
      "iter [6120] loss:0.1982   | 2.9834sec\n",
      "iter [6130] loss:0.1707   | 3.0119sec\n",
      "iter [6140] loss:0.3222   | 3.0048sec\n",
      "iter [6150] loss:0.3579   | 2.9953sec\n",
      "iter [6160] loss:0.2205   | 3.0155sec\n",
      "iter [6170] loss:0.1913   | 2.9962sec\n",
      "iter [6180] loss:0.3174   | 3.0176sec\n",
      "iter [6190] loss:0.2796   | 3.0094sec\n",
      "iter [6200] loss:0.3380   | 3.0126sec\n",
      "iter [6210] loss:0.1427   | 2.9968sec\n",
      "iter [6220] loss:0.4578   | 3.0110sec\n",
      "epoch [17] train loss:0.2405, val loss:0.0000  | 118.2271sec\n",
      "=====Epoch 18/30=====\n",
      "[train]\n",
      "iter [6230] loss:0.2722   | 2.4332sec\n",
      "iter [6240] loss:0.1171   | 3.0173sec\n",
      "iter [6250] loss:0.2536   | 3.0302sec\n",
      "iter [6260] loss:0.1838   | 2.9689sec\n",
      "iter [6270] loss:0.1947   | 2.9950sec\n",
      "iter [6280] loss:0.1275   | 2.9985sec\n",
      "iter [6290] loss:0.2749   | 3.0033sec\n",
      "iter [6300] loss:0.2181   | 3.0365sec\n",
      "iter [6310] loss:0.1517   | 3.0193sec\n",
      "iter [6320] loss:0.2355   | 3.0118sec\n",
      "iter [6330] loss:0.1775   | 2.9985sec\n",
      "iter [6340] loss:0.3302   | 2.9971sec\n",
      "iter [6350] loss:0.4268   | 2.9798sec\n",
      "iter [6360] loss:0.2987   | 2.9935sec\n",
      "iter [6370] loss:0.2534   | 2.9975sec\n",
      "iter [6380] loss:0.3107   | 2.9931sec\n",
      "iter [6390] loss:0.6234   | 3.0060sec\n",
      "iter [6400] loss:0.1504   | 3.0218sec\n",
      "iter [6410] loss:0.1790   | 3.0042sec\n",
      "iter [6420] loss:0.2663   | 3.0134sec\n",
      "iter [6430] loss:0.2179   | 3.0057sec\n",
      "iter [6440] loss:0.2600   | 3.0197sec\n",
      "iter [6450] loss:0.2308   | 3.0233sec\n",
      "iter [6460] loss:0.3823   | 2.9948sec\n",
      "iter [6470] loss:0.1669   | 2.9845sec\n",
      "iter [6480] loss:0.1555   | 3.0024sec\n",
      "iter [6490] loss:0.2865   | 2.9936sec\n",
      "iter [6500] loss:0.2607   | 3.0009sec\n",
      "iter [6510] loss:0.2102   | 3.0145sec\n",
      "iter [6520] loss:0.2131   | 2.9878sec\n",
      "iter [6530] loss:0.1461   | 3.0117sec\n",
      "iter [6540] loss:0.1615   | 3.0077sec\n",
      "iter [6550] loss:0.2137   | 3.0136sec\n",
      "iter [6560] loss:0.2249   | 3.0038sec\n",
      "iter [6570] loss:0.3237   | 3.0060sec\n",
      "iter [6580] loss:0.2317   | 3.0186sec\n",
      "epoch [18] train loss:0.2360, val loss:0.0000  | 118.1381sec\n",
      "=====Epoch 19/30=====\n",
      "[train]\n",
      "iter [6590] loss:0.1972   | 0.4440sec\n",
      "iter [6600] loss:0.2947   | 2.9953sec\n",
      "iter [6610] loss:0.1367   | 3.0178sec\n",
      "iter [6620] loss:0.7619   | 3.0124sec\n",
      "iter [6630] loss:0.1577   | 3.0055sec\n",
      "iter [6640] loss:0.2015   | 3.0089sec\n",
      "iter [6650] loss:0.3323   | 2.9738sec\n",
      "iter [6660] loss:0.2937   | 2.9988sec\n",
      "iter [6670] loss:0.1441   | 3.0044sec\n",
      "iter [6680] loss:0.2364   | 3.0284sec\n",
      "iter [6690] loss:0.1541   | 2.9903sec\n",
      "iter [6700] loss:0.2404   | 3.0268sec\n",
      "iter [6710] loss:0.1840   | 3.0131sec\n",
      "iter [6720] loss:0.3072   | 2.9918sec\n",
      "iter [6730] loss:0.0954   | 3.0040sec\n",
      "iter [6740] loss:0.2432   | 3.0072sec\n",
      "iter [6750] loss:0.1878   | 2.9958sec\n",
      "iter [6760] loss:0.1814   | 3.0170sec\n",
      "iter [6770] loss:0.0749   | 2.9903sec\n",
      "iter [6780] loss:0.4731   | 3.0180sec\n",
      "iter [6790] loss:0.3688   | 3.0182sec\n",
      "iter [6800] loss:0.1945   | 3.0244sec\n",
      "iter [6810] loss:0.2493   | 3.0075sec\n",
      "iter [6820] loss:0.2437   | 2.9960sec\n",
      "iter [6830] loss:0.2282   | 2.9839sec\n",
      "iter [6840] loss:0.2948   | 3.0004sec\n",
      "iter [6850] loss:0.3209   | 3.0173sec\n",
      "iter [6860] loss:0.1954   | 3.0228sec\n",
      "iter [6870] loss:0.1445   | 3.0351sec\n",
      "iter [6880] loss:0.1605   | 3.0092sec\n",
      "iter [6890] loss:0.1733   | 3.0159sec\n",
      "iter [6900] loss:0.2338   | 2.9830sec\n",
      "iter [6910] loss:0.2449   | 3.0068sec\n",
      "iter [6920] loss:0.3730   | 3.0138sec\n",
      "iter [6930] loss:0.1610   | 3.0198sec\n",
      "iter [6940] loss:0.2068   | 3.0087sec\n",
      "iter [6950] loss:0.0984   | 3.0022sec\n",
      "epoch [19] train loss:0.2415, val loss:0.0000  | 118.1849sec\n",
      "=====Epoch 20/30=====\n",
      "[train]\n",
      "iter [6960] loss:0.1183   | 1.7925sec\n",
      "iter [6970] loss:0.4101   | 2.9932sec\n",
      "iter [6980] loss:0.3923   | 3.0210sec\n",
      "iter [6990] loss:0.1788   | 2.9978sec\n",
      "iter [7000] loss:0.2357   | 3.0380sec\n",
      "iter [7010] loss:0.1969   | 3.0026sec\n",
      "iter [7020] loss:0.3141   | 3.0037sec\n",
      "iter [7030] loss:0.1415   | 2.9960sec\n",
      "iter [7040] loss:0.1993   | 3.0051sec\n",
      "iter [7050] loss:0.1578   | 2.9946sec\n",
      "iter [7060] loss:0.1803   | 3.0190sec\n",
      "iter [7070] loss:0.4934   | 3.0028sec\n",
      "iter [7080] loss:0.0989   | 2.9871sec\n",
      "iter [7090] loss:0.2514   | 3.0162sec\n",
      "iter [7100] loss:0.2148   | 3.0160sec\n",
      "iter [7110] loss:0.2917   | 3.0069sec\n",
      "iter [7120] loss:0.1508   | 2.9825sec\n",
      "iter [7130] loss:0.1948   | 3.0130sec\n",
      "iter [7140] loss:0.1682   | 3.0044sec\n",
      "iter [7150] loss:0.3585   | 2.9987sec\n",
      "iter [7160] loss:0.2131   | 3.0228sec\n",
      "iter [7170] loss:0.1970   | 3.0203sec\n",
      "iter [7180] loss:0.1552   | 2.9919sec\n",
      "iter [7190] loss:0.3190   | 2.9899sec\n",
      "iter [7200] loss:0.2009   | 3.0052sec\n",
      "iter [7210] loss:0.1725   | 2.9998sec\n",
      "iter [7220] loss:0.4914   | 3.0109sec\n",
      "iter [7230] loss:0.3188   | 3.0254sec\n",
      "iter [7240] loss:0.2749   | 3.0044sec\n",
      "iter [7250] loss:0.1574   | 3.0209sec\n",
      "iter [7260] loss:0.1226   | 3.0270sec\n",
      "iter [7270] loss:0.1921   | 2.9903sec\n",
      "iter [7280] loss:0.2179   | 3.0126sec\n",
      "iter [7290] loss:0.4184   | 3.0182sec\n",
      "iter [7300] loss:0.2971   | 3.0245sec\n",
      "iter [7310] loss:0.2937   | 2.9998sec\n",
      "iter [7320] loss:0.5194   | 3.0059sec\n",
      "epoch [20] train loss:0.2358, val loss:0.0000  | 118.2440sec\n",
      "[val]\n",
      "epoch [20] train loss:0.2358, val loss:0.2802  | 38.0489sec\n",
      "=====Epoch 21/30=====\n",
      "[train]\n",
      "iter [7330] loss:0.1708   | 3.0369sec\n",
      "iter [7340] loss:0.4232   | 3.0083sec\n",
      "iter [7350] loss:0.2388   | 3.0039sec\n",
      "iter [7360] loss:0.1552   | 3.0128sec\n",
      "iter [7370] loss:0.2419   | 2.9995sec\n",
      "iter [7380] loss:0.1546   | 2.9947sec\n",
      "iter [7390] loss:0.1593   | 3.0225sec\n",
      "iter [7400] loss:0.1644   | 3.0030sec\n",
      "iter [7410] loss:0.3054   | 3.0222sec\n",
      "iter [7420] loss:0.2311   | 3.0078sec\n",
      "iter [7430] loss:0.2975   | 3.0228sec\n",
      "iter [7440] loss:0.2577   | 3.0173sec\n",
      "iter [7450] loss:0.1992   | 3.0369sec\n",
      "iter [7460] loss:0.1365   | 3.0194sec\n",
      "iter [7470] loss:0.2818   | 2.9872sec\n",
      "iter [7480] loss:0.3585   | 3.0003sec\n",
      "iter [7490] loss:0.1505   | 3.0248sec\n",
      "iter [7500] loss:0.1110   | 2.9915sec\n",
      "iter [7510] loss:0.4266   | 3.0091sec\n",
      "iter [7520] loss:0.2416   | 3.0053sec\n",
      "iter [7530] loss:0.2010   | 3.0114sec\n",
      "iter [7540] loss:0.1275   | 2.9984sec\n",
      "iter [7550] loss:0.2440   | 2.9992sec\n",
      "iter [7560] loss:0.3755   | 3.0207sec\n",
      "iter [7570] loss:0.2209   | 3.0061sec\n",
      "iter [7580] loss:0.2361   | 3.0070sec\n",
      "iter [7590] loss:0.1474   | 3.0064sec\n",
      "iter [7600] loss:0.2913   | 3.0076sec\n",
      "iter [7610] loss:0.2411   | 3.0114sec\n",
      "iter [7620] loss:0.1944   | 3.0071sec\n",
      "iter [7630] loss:0.1564   | 3.0186sec\n",
      "iter [7640] loss:0.3601   | 2.9912sec\n",
      "iter [7650] loss:0.1359   | 3.0021sec\n",
      "iter [7660] loss:0.2143   | 3.0035sec\n",
      "iter [7670] loss:0.2874   | 3.0557sec\n",
      "iter [7680] loss:0.2578   | 3.0330sec\n",
      "epoch [21] train loss:0.2335, val loss:0.0000  | 118.3393sec\n",
      "=====Epoch 22/30=====\n",
      "[train]\n",
      "iter [7690] loss:0.3200   | 1.1072sec\n",
      "iter [7700] loss:0.2863   | 3.0188sec\n",
      "iter [7710] loss:0.3034   | 3.0054sec\n",
      "iter [7720] loss:0.3061   | 3.0166sec\n",
      "iter [7730] loss:0.1971   | 3.0218sec\n",
      "iter [7740] loss:0.1380   | 3.0005sec\n",
      "iter [7750] loss:0.1227   | 3.0109sec\n",
      "iter [7760] loss:0.2909   | 2.9937sec\n",
      "iter [7770] loss:0.1393   | 3.0033sec\n",
      "iter [7780] loss:0.0943   | 3.0179sec\n",
      "iter [7790] loss:0.1957   | 3.0067sec\n",
      "iter [7800] loss:0.2131   | 3.0090sec\n",
      "iter [7810] loss:0.1650   | 3.0151sec\n",
      "iter [7820] loss:0.1636   | 3.0026sec\n",
      "iter [7830] loss:0.1748   | 2.9940sec\n",
      "iter [7840] loss:0.2882   | 3.0069sec\n",
      "iter [7850] loss:0.0927   | 3.0129sec\n",
      "iter [7860] loss:0.1908   | 2.9923sec\n",
      "iter [7870] loss:0.2049   | 3.0286sec\n",
      "iter [7880] loss:0.2477   | 2.9931sec\n",
      "iter [7890] loss:0.2571   | 3.0071sec\n",
      "iter [7900] loss:0.2888   | 3.0194sec\n",
      "iter [7910] loss:0.1183   | 3.0098sec\n",
      "iter [7920] loss:0.2952   | 3.0186sec\n",
      "iter [7930] loss:0.2778   | 3.0096sec\n",
      "iter [7940] loss:0.1322   | 3.0190sec\n",
      "iter [7950] loss:0.1756   | 2.9837sec\n",
      "iter [7960] loss:0.2010   | 3.0158sec\n",
      "iter [7970] loss:0.2742   | 3.0058sec\n",
      "iter [7980] loss:0.1747   | 3.0024sec\n",
      "iter [7990] loss:0.3637   | 2.9995sec\n",
      "iter [8000] loss:0.1739   | 3.0293sec\n",
      "iter [8010] loss:0.3195   | 3.0078sec\n",
      "iter [8020] loss:0.1529   | 2.9982sec\n",
      "iter [8030] loss:0.2730   | 3.0051sec\n",
      "iter [8040] loss:0.1025   | 3.0130sec\n",
      "iter [8050] loss:0.2262   | 3.0146sec\n",
      "epoch [22] train loss:0.2362, val loss:0.0000  | 118.2481sec\n",
      "=====Epoch 23/30=====\n",
      "[train]\n",
      "iter [8060] loss:0.1783   | 2.4511sec\n",
      "iter [8070] loss:0.1297   | 2.9903sec\n",
      "iter [8080] loss:0.4145   | 2.9963sec\n",
      "iter [8090] loss:0.1141   | 2.9928sec\n",
      "iter [8100] loss:0.1128   | 2.9997sec\n",
      "iter [8110] loss:0.2855   | 3.0061sec\n",
      "iter [8120] loss:0.2557   | 2.9783sec\n",
      "iter [8130] loss:0.1302   | 2.9886sec\n",
      "iter [8140] loss:0.1597   | 2.9986sec\n",
      "iter [8150] loss:0.1925   | 3.0327sec\n",
      "iter [8160] loss:0.4251   | 3.0341sec\n",
      "iter [8170] loss:0.2018   | 3.0102sec\n",
      "iter [8180] loss:0.1811   | 3.0111sec\n",
      "iter [8190] loss:0.6423   | 3.0123sec\n",
      "iter [8200] loss:0.1336   | 2.9931sec\n",
      "iter [8210] loss:0.0866   | 3.0008sec\n",
      "iter [8220] loss:0.1518   | 2.9988sec\n",
      "iter [8230] loss:0.1050   | 3.0125sec\n",
      "iter [8240] loss:0.1339   | 3.0043sec\n",
      "iter [8250] loss:0.2842   | 3.0024sec\n",
      "iter [8260] loss:0.1256   | 3.0166sec\n",
      "iter [8270] loss:0.2147   | 3.0093sec\n",
      "iter [8280] loss:0.2471   | 3.0040sec\n",
      "iter [8290] loss:0.2318   | 3.0017sec\n",
      "iter [8300] loss:0.1529   | 3.0140sec\n",
      "iter [8310] loss:0.2868   | 3.0064sec\n",
      "iter [8320] loss:0.3194   | 3.0129sec\n",
      "iter [8330] loss:0.1688   | 3.0315sec\n",
      "iter [8340] loss:0.1870   | 3.0192sec\n",
      "iter [8350] loss:0.2006   | 3.0210sec\n",
      "iter [8360] loss:0.1117   | 3.0277sec\n",
      "iter [8370] loss:0.3696   | 3.0073sec\n",
      "iter [8380] loss:0.3213   | 2.9912sec\n",
      "iter [8390] loss:0.3409   | 3.0232sec\n",
      "iter [8400] loss:0.3559   | 3.0080sec\n",
      "iter [8410] loss:0.1976   | 3.0234sec\n",
      "epoch [23] train loss:0.2255, val loss:0.0000  | 118.2630sec\n",
      "=====Epoch 24/30=====\n",
      "[train]\n",
      "iter [8420] loss:0.2369   | 0.4735sec\n",
      "iter [8430] loss:0.1938   | 3.0150sec\n",
      "iter [8440] loss:0.1591   | 3.0278sec\n",
      "iter [8450] loss:0.3482   | 3.0157sec\n",
      "iter [8460] loss:0.1424   | 3.0063sec\n",
      "iter [8470] loss:0.4347   | 3.0113sec\n",
      "iter [8480] loss:0.3704   | 2.9929sec\n",
      "iter [8490] loss:0.3388   | 3.0187sec\n",
      "iter [8500] loss:0.6221   | 3.0226sec\n",
      "iter [8510] loss:0.1991   | 3.0198sec\n",
      "iter [8520] loss:0.5763   | 2.9994sec\n",
      "iter [8530] loss:0.2078   | 3.0023sec\n",
      "iter [8540] loss:0.2167   | 3.0324sec\n",
      "iter [8550] loss:0.1648   | 2.9965sec\n",
      "iter [8560] loss:0.2050   | 3.0291sec\n",
      "iter [8570] loss:0.1817   | 2.9979sec\n",
      "iter [8580] loss:0.3596   | 2.9820sec\n",
      "iter [8590] loss:0.1302   | 3.0094sec\n",
      "iter [8600] loss:0.1912   | 3.0189sec\n",
      "iter [8610] loss:0.1812   | 3.0016sec\n",
      "iter [8620] loss:0.1926   | 3.0318sec\n",
      "iter [8630] loss:0.1266   | 2.9895sec\n",
      "iter [8640] loss:0.3024   | 3.0285sec\n",
      "iter [8650] loss:0.4225   | 3.0035sec\n",
      "iter [8660] loss:0.2058   | 2.9997sec\n",
      "iter [8670] loss:0.2151   | 3.0120sec\n",
      "iter [8680] loss:0.3274   | 3.0142sec\n",
      "iter [8690] loss:0.2567   | 2.9970sec\n",
      "iter [8700] loss:0.1351   | 3.0056sec\n",
      "iter [8710] loss:0.1654   | 3.0119sec\n",
      "iter [8720] loss:0.0756   | 3.0123sec\n",
      "iter [8730] loss:0.1847   | 3.0243sec\n",
      "iter [8740] loss:0.1834   | 3.0065sec\n",
      "iter [8750] loss:0.2107   | 3.0054sec\n",
      "iter [8760] loss:0.1400   | 3.0269sec\n",
      "iter [8770] loss:0.3484   | 3.0045sec\n",
      "iter [8780] loss:0.2357   | 3.0247sec\n",
      "epoch [24] train loss:0.2295, val loss:0.0000  | 118.3578sec\n",
      "=====Epoch 25/30=====\n",
      "[train]\n",
      "iter [8790] loss:0.1967   | 1.8108sec\n",
      "iter [8800] loss:0.1720   | 3.0364sec\n",
      "iter [8810] loss:0.2934   | 3.0019sec\n",
      "iter [8820] loss:0.1659   | 2.9946sec\n",
      "iter [8830] loss:0.2293   | 3.0154sec\n",
      "iter [8840] loss:0.1873   | 3.0186sec\n",
      "iter [8850] loss:0.1082   | 3.0130sec\n",
      "iter [8860] loss:0.1027   | 3.0019sec\n",
      "iter [8870] loss:0.3769   | 3.0192sec\n",
      "iter [8880] loss:0.1964   | 3.0003sec\n",
      "iter [8890] loss:0.1787   | 3.0100sec\n",
      "iter [8900] loss:0.3034   | 3.0079sec\n",
      "iter [8910] loss:0.1381   | 3.0157sec\n",
      "iter [8920] loss:0.1921   | 3.0241sec\n",
      "iter [8930] loss:0.5301   | 2.9972sec\n",
      "iter [8940] loss:0.2364   | 3.0254sec\n",
      "iter [8950] loss:0.1798   | 3.0401sec\n",
      "iter [8960] loss:0.1380   | 3.0030sec\n",
      "iter [8970] loss:0.2118   | 3.0250sec\n",
      "iter [8980] loss:0.2561   | 2.9902sec\n",
      "iter [8990] loss:0.2162   | 2.9947sec\n",
      "iter [9000] loss:0.2230   | 3.0137sec\n",
      "iter [9010] loss:0.1503   | 3.0076sec\n",
      "iter [9020] loss:0.4828   | 3.0129sec\n",
      "iter [9030] loss:0.2915   | 3.0093sec\n",
      "iter [9040] loss:0.2151   | 3.0107sec\n",
      "iter [9050] loss:0.2188   | 3.0285sec\n",
      "iter [9060] loss:0.5313   | 3.0021sec\n",
      "iter [9070] loss:0.1562   | 3.0004sec\n",
      "iter [9080] loss:0.2854   | 2.9783sec\n",
      "iter [9090] loss:0.3215   | 2.9950sec\n",
      "iter [9100] loss:0.4099   | 3.0150sec\n",
      "iter [9110] loss:0.2279   | 3.0060sec\n",
      "iter [9120] loss:0.3790   | 3.0161sec\n",
      "iter [9130] loss:0.1642   | 3.0228sec\n",
      "iter [9140] loss:0.1424   | 3.0018sec\n",
      "iter [9150] loss:0.2305   | 2.9975sec\n",
      "epoch [25] train loss:0.2336, val loss:0.0000  | 118.3356sec\n",
      "[val]\n",
      "epoch [25] train loss:0.2336, val loss:0.2755  | 38.0001sec\n",
      "=====Epoch 26/30=====\n",
      "[train]\n",
      "iter [9160] loss:0.1457   | 3.0796sec\n",
      "iter [9170] loss:0.1732   | 2.9985sec\n",
      "iter [9180] loss:0.1645   | 3.0130sec\n",
      "iter [9190] loss:0.1061   | 3.0238sec\n",
      "iter [9200] loss:0.2680   | 3.0093sec\n",
      "iter [9210] loss:0.2977   | 2.9939sec\n",
      "iter [9220] loss:0.1823   | 3.0378sec\n",
      "iter [9230] loss:0.1696   | 2.9919sec\n",
      "iter [9240] loss:0.1834   | 2.9868sec\n",
      "iter [9250] loss:0.1419   | 3.0085sec\n",
      "iter [9260] loss:0.1081   | 2.9953sec\n",
      "iter [9270] loss:0.4258   | 3.0084sec\n",
      "iter [9280] loss:0.1553   | 3.0323sec\n",
      "iter [9290] loss:0.1752   | 3.0113sec\n",
      "iter [9300] loss:0.0960   | 3.0126sec\n",
      "iter [9310] loss:0.1950   | 3.0098sec\n",
      "iter [9320] loss:0.1571   | 3.0232sec\n",
      "iter [9330] loss:0.4282   | 3.0208sec\n",
      "iter [9340] loss:0.1622   | 3.0001sec\n",
      "iter [9350] loss:0.4078   | 3.0014sec\n",
      "iter [9360] loss:0.1964   | 3.0133sec\n",
      "iter [9370] loss:0.2320   | 3.0150sec\n",
      "iter [9380] loss:0.5233   | 3.0007sec\n",
      "iter [9390] loss:0.3335   | 2.9910sec\n",
      "iter [9400] loss:0.2438   | 3.0054sec\n",
      "iter [9410] loss:0.1826   | 2.9998sec\n",
      "iter [9420] loss:0.1219   | 2.9921sec\n",
      "iter [9430] loss:0.3129   | 3.0144sec\n",
      "iter [9440] loss:0.1671   | 3.0079sec\n",
      "iter [9450] loss:0.1349   | 2.9913sec\n",
      "iter [9460] loss:0.1121   | 2.9969sec\n",
      "iter [9470] loss:0.2425   | 3.0147sec\n",
      "iter [9480] loss:0.1576   | 3.0110sec\n",
      "iter [9490] loss:0.1474   | 2.9925sec\n",
      "iter [9500] loss:0.1498   | 3.0372sec\n",
      "iter [9510] loss:0.1448   | 3.0034sec\n",
      "epoch [26] train loss:0.2247, val loss:0.0000  | 118.2569sec\n",
      "=====Epoch 27/30=====\n",
      "[train]\n",
      "iter [9520] loss:0.1477   | 1.0857sec\n",
      "iter [9530] loss:0.2707   | 3.0203sec\n",
      "iter [9540] loss:0.2093   | 2.9885sec\n",
      "iter [9550] loss:0.1673   | 2.9964sec\n",
      "iter [9560] loss:0.3493   | 3.0031sec\n",
      "iter [9570] loss:0.1787   | 3.0096sec\n",
      "iter [9580] loss:0.2546   | 2.9961sec\n",
      "iter [9590] loss:0.4037   | 2.9935sec\n",
      "iter [9600] loss:0.2356   | 2.9950sec\n",
      "iter [9610] loss:0.0546   | 2.9931sec\n",
      "iter [9620] loss:0.2891   | 3.0171sec\n",
      "iter [9630] loss:0.1674   | 3.0021sec\n",
      "iter [9640] loss:0.2297   | 2.9900sec\n",
      "iter [9650] loss:0.1196   | 3.0153sec\n",
      "iter [9660] loss:0.1475   | 2.9952sec\n",
      "iter [9670] loss:0.1442   | 3.0115sec\n",
      "iter [9680] loss:0.1865   | 3.0291sec\n",
      "iter [9690] loss:0.1832   | 3.0051sec\n",
      "iter [9700] loss:0.1396   | 2.9933sec\n",
      "iter [9710] loss:0.2846   | 3.0171sec\n",
      "iter [9720] loss:0.1818   | 3.0550sec\n",
      "iter [9730] loss:0.1586   | 3.0087sec\n",
      "iter [9740] loss:0.0762   | 2.9974sec\n",
      "iter [9750] loss:0.2867   | 3.0153sec\n",
      "iter [9760] loss:0.1968   | 2.9982sec\n",
      "iter [9770] loss:0.4773   | 3.0137sec\n",
      "iter [9780] loss:0.2654   | 3.0045sec\n",
      "iter [9790] loss:0.1601   | 3.0094sec\n",
      "iter [9800] loss:0.1766   | 2.9928sec\n",
      "iter [9810] loss:0.3308   | 3.0059sec\n",
      "iter [9820] loss:0.2970   | 3.0245sec\n",
      "iter [9830] loss:0.2140   | 3.0081sec\n",
      "iter [9840] loss:0.4211   | 2.9925sec\n",
      "iter [9850] loss:0.1769   | 3.0340sec\n",
      "iter [9860] loss:0.2426   | 3.0036sec\n",
      "iter [9870] loss:0.1592   | 3.0124sec\n",
      "iter [9880] loss:0.2698   | 3.0121sec\n",
      "epoch [27] train loss:0.2155, val loss:0.0000  | 118.1713sec\n",
      "=====Epoch 28/30=====\n",
      "[train]\n",
      "iter [9890] loss:0.3074   | 2.4537sec\n",
      "iter [9900] loss:0.2470   | 3.0289sec\n",
      "iter [9910] loss:0.1472   | 3.0101sec\n",
      "iter [9920] loss:0.1821   | 3.0073sec\n",
      "iter [9930] loss:0.1735   | 3.0226sec\n",
      "iter [9940] loss:0.2849   | 3.0287sec\n",
      "iter [9950] loss:0.1109   | 3.1454sec\n",
      "iter [9960] loss:0.3087   | 2.9255sec\n",
      "iter [9970] loss:0.1573   | 2.9198sec\n",
      "iter [9980] loss:0.1098   | 3.0765sec\n",
      "iter [9990] loss:0.1407   | 2.9939sec\n",
      "iter [10000] loss:0.2655   | 2.9635sec\n",
      "iter [10010] loss:0.1648   | 2.9491sec\n",
      "iter [10020] loss:0.1509   | 2.9436sec\n",
      "iter [10030] loss:0.1767   | 2.9274sec\n",
      "iter [10040] loss:0.1910   | 2.9386sec\n",
      "iter [10050] loss:0.3633   | 2.9551sec\n",
      "iter [10060] loss:0.4146   | 2.9666sec\n",
      "iter [10070] loss:0.1138   | 2.9444sec\n",
      "iter [10080] loss:0.2561   | 2.9107sec\n",
      "iter [10090] loss:0.1590   | 2.9467sec\n",
      "iter [10100] loss:0.3991   | 2.9561sec\n",
      "iter [10110] loss:0.1671   | 2.9262sec\n",
      "iter [10120] loss:0.0973   | 2.9578sec\n",
      "iter [10130] loss:0.2840   | 2.9469sec\n",
      "iter [10140] loss:0.1756   | 2.9249sec\n",
      "iter [10150] loss:0.1490   | 2.9414sec\n",
      "iter [10160] loss:0.2026   | 2.9012sec\n",
      "iter [10170] loss:0.2791   | 2.9527sec\n",
      "iter [10180] loss:0.1668   | 2.9672sec\n",
      "iter [10190] loss:0.1169   | 2.9556sec\n",
      "iter [10200] loss:0.2448   | 2.9190sec\n",
      "iter [10210] loss:0.3565   | 2.9182sec\n",
      "iter [10220] loss:0.2031   | 2.9452sec\n",
      "iter [10230] loss:0.3132   | 2.9593sec\n",
      "iter [10240] loss:0.3349   | 2.9482sec\n",
      "epoch [28] train loss:0.2283, val loss:0.0000  | 116.6491sec\n",
      "=====Epoch 29/30=====\n",
      "[train]\n",
      "iter [10250] loss:0.1219   | 0.4490sec\n",
      "iter [10260] loss:0.2222   | 2.9491sec\n",
      "iter [10270] loss:0.1216   | 2.9528sec\n",
      "iter [10280] loss:0.2883   | 2.9451sec\n",
      "iter [10290] loss:0.2667   | 2.9289sec\n",
      "iter [10300] loss:0.1897   | 2.9591sec\n",
      "iter [10310] loss:0.2105   | 2.9482sec\n",
      "iter [10320] loss:0.2434   | 2.9225sec\n",
      "iter [10330] loss:0.2060   | 2.9569sec\n",
      "iter [10340] loss:0.2738   | 2.9398sec\n",
      "iter [10350] loss:0.2741   | 2.9431sec\n",
      "iter [10360] loss:0.2051   | 2.9410sec\n",
      "iter [10370] loss:0.0876   | 2.9140sec\n",
      "iter [10380] loss:0.1388   | 2.9167sec\n",
      "iter [10390] loss:0.1759   | 2.9249sec\n",
      "iter [10400] loss:0.1303   | 2.9392sec\n",
      "iter [10410] loss:0.1187   | 2.9357sec\n",
      "iter [10420] loss:0.1942   | 2.9612sec\n",
      "iter [10430] loss:0.2491   | 2.9909sec\n",
      "iter [10440] loss:0.2526   | 2.9430sec\n",
      "iter [10450] loss:0.1845   | 2.9169sec\n",
      "iter [10460] loss:0.2586   | 2.9497sec\n",
      "iter [10470] loss:0.1813   | 2.9343sec\n",
      "iter [10480] loss:0.0901   | 2.9501sec\n",
      "iter [10490] loss:0.1756   | 2.9761sec\n",
      "iter [10500] loss:0.1529   | 2.9074sec\n",
      "iter [10510] loss:0.2363   | 2.9519sec\n",
      "iter [10520] loss:0.2886   | 2.9325sec\n",
      "iter [10530] loss:0.1911   | 2.9325sec\n",
      "iter [10540] loss:0.4570   | 2.9381sec\n",
      "iter [10550] loss:0.1685   | 2.9439sec\n",
      "iter [10560] loss:0.2464   | 2.9622sec\n",
      "iter [10570] loss:0.1034   | 2.9795sec\n",
      "iter [10580] loss:0.2825   | 2.9336sec\n",
      "iter [10590] loss:0.1931   | 2.9309sec\n",
      "iter [10600] loss:0.3491   | 2.9241sec\n",
      "iter [10610] loss:0.2029   | 2.9753sec\n",
      "epoch [29] train loss:0.2205, val loss:0.0000  | 115.8497sec\n",
      "=====Epoch 30/30=====\n",
      "[train]\n",
      "iter [10620] loss:0.2734   | 1.7417sec\n",
      "iter [10630] loss:0.1855   | 2.9511sec\n",
      "iter [10640] loss:0.1584   | 2.9270sec\n",
      "iter [10650] loss:0.1344   | 2.9031sec\n",
      "iter [10660] loss:0.2294   | 2.9411sec\n",
      "iter [10670] loss:0.0859   | 2.9463sec\n",
      "iter [10680] loss:0.6707   | 2.9395sec\n",
      "iter [10690] loss:0.3071   | 2.9318sec\n",
      "iter [10700] loss:0.2041   | 2.9495sec\n",
      "iter [10710] loss:0.2126   | 2.9232sec\n",
      "iter [10720] loss:0.1583   | 2.9419sec\n",
      "iter [10730] loss:0.1718   | 2.9512sec\n",
      "iter [10740] loss:0.2593   | 2.9366sec\n",
      "iter [10750] loss:0.1678   | 2.9440sec\n",
      "iter [10760] loss:0.2082   | 2.9457sec\n",
      "iter [10770] loss:0.1232   | 2.9652sec\n",
      "iter [10780] loss:0.2293   | 2.9369sec\n",
      "iter [10790] loss:0.1668   | 2.9418sec\n",
      "iter [10800] loss:0.0953   | 2.9108sec\n",
      "iter [10810] loss:0.1410   | 2.9234sec\n",
      "iter [10820] loss:0.2289   | 2.9248sec\n",
      "iter [10830] loss:0.2671   | 2.9502sec\n",
      "iter [10840] loss:0.2270   | 2.9361sec\n",
      "iter [10850] loss:0.1301   | 2.9499sec\n",
      "iter [10860] loss:0.4440   | 2.9506sec\n",
      "iter [10870] loss:0.1758   | 2.9612sec\n",
      "iter [10880] loss:0.2213   | 2.9459sec\n",
      "iter [10890] loss:0.3393   | 2.9336sec\n",
      "iter [10900] loss:0.2202   | 2.9409sec\n",
      "iter [10910] loss:0.2449   | 2.9456sec\n",
      "iter [10920] loss:0.1416   | 2.9309sec\n",
      "iter [10930] loss:0.2161   | 2.9463sec\n",
      "iter [10940] loss:0.1995   | 2.9310sec\n",
      "iter [10950] loss:0.3934   | 2.9171sec\n",
      "iter [10960] loss:0.1332   | 2.9478sec\n",
      "iter [10970] loss:0.1549   | 2.9320sec\n",
      "iter [10980] loss:0.1748   | 2.9337sec\n",
      "epoch [30] train loss:0.2220, val loss:0.0000  | 115.7137sec\n",
      "[val]\n",
      "epoch [30] train loss:0.2220, val loss:0.2768  | 38.0332sec\n"
     ]
    }
   ],
   "source": [
    "num_epochs=30\n",
    "train_model(net,dataloaders_dict,criterion,scheduler,optimizer,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "415c659548b03e5a7ab126dcfbb4fc7162127f64c5d6abf067896d088a8939b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorchDeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
