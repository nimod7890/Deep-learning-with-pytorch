{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import makeDatapathList,dataTransform,VOCDataset\n",
    "\n",
    "root_path=\"./data/VOCdevkit/VOC2012/\"\n",
    "\n",
    "datapath_list=makeDatapathList(root_path)\n",
    "train_img_list,train_anno_list=datapath_list('train')\n",
    "val_img_list,val_anno_list=datapath_list('val')\n",
    "\n",
    "color_mean=(0.485,0.456,0.406)\n",
    "color_std=(0.29,0.224,0.225)\n",
    "\n",
    "transform=dataTransform(475,color_mean,color_std)\n",
    "train_dataset=VOCDataset(train_img_list,train_anno_list,phase=\"train\",transform=transform)\n",
    "val_dataset=VOCDataset(val_img_list,val_anno_list,phase=\"val\",transform=transform)\n",
    "\n",
    "batch_size=8\n",
    "train_dataloader=data.DataLoader(train_dataset,batch_size,True)\n",
    "val_dataloader=data.DataLoader(val_dataset,batch_size,False)\n",
    "\n",
    "dataloaders_dict={\"train\":train_dataloader,\"val\":val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pspnet import PSPNet\n",
    "\n",
    "net=PSPNet(n_classes=150)\n",
    "\n",
    "state_dict=torch.load(\"./weights/pspnet50_ADE20K.pth\") #fine tuning\n",
    "net.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "n_classes=21\n",
    "net.decode_feature.classification=nn.Conv2d(in_channels=512,out_channels=n_classes,kernel_size=1,stride=1,padding=0)\n",
    "net.aux.classification=nn.Conv2d(in_channels=256,out_channels=n_classes,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m,nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias,0.0)\n",
    "\n",
    "net.decode_feature.classification.apply(weights_init)\n",
    "net.aux.classification.apply(weights_init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPLoss(nn.Module):\n",
    "    def __init__(self,aux_weight=0.4):\n",
    "        super(PSPLoss,self).__init__()\n",
    "        self.aux_weight=aux_weight\n",
    "    \n",
    "    def forward(self,outputs,targets):\n",
    "        loss=F.cross_entropy(outputs[0],targets,reduction='mean')\n",
    "        loss_aux=F.cross_entropy(outputs[1],targets,reduction='mean')\n",
    "        return loss+self.aux_weight*loss_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=PSPLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=optim.SGD([\n",
    "    {'params':net.feature_conv.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_res_1.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_res_2.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_dilated_res_1.parameters(),'lr':1e-3},\n",
    "    {'params':net.feature_dilated_res_2.parameters(),'lr':1e-3},\n",
    "    {'params':net.pyramid_pooling.parameters(),'lr':1e-3},\n",
    "    {'params':net.decode_feature.parameters(),'lr':1e-3},\n",
    "    {'params':net.aux.parameters(),'lr':1e-3},\n",
    "],momentum=0.9,weight_decay=0.0001)\n",
    "\n",
    "def lambda_epoch(epoch):\n",
    "    max_epoch=30\n",
    "    return math.pow((1-epoch/max_epoch),0.9)\n",
    "\n",
    "scheduler=optim.lr_scheduler.LambdaLR(optimizer,lr_lambda=lambda_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net,dataloaders_dict,criterion,scheduler,optimizer,num_epochs):\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    net.to(device)\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    num_train_imgs=len(dataloaders_dict[\"train\"].dataset)\n",
    "    num_val_imgs=len(dataloaders_dict[\"val\"].dataset)\n",
    "    \n",
    "    batch_size=dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    iteration=1\n",
    "    logs=[]\n",
    "\n",
    "    batch_multiplier=3\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t_epoch_start=time.time()\n",
    "        t_iter_start=time.time()\n",
    "        epoch_train_loss=0.0\n",
    "        epoch_val_loss=0.0\n",
    "\n",
    "        print(f\"{'='*5}Epoch {epoch+1}/{num_epochs}{'='*5}\")\n",
    "        for phase in [\"train\",\"val\"]:\n",
    "            if phase==\"train\":\n",
    "                net.train()\n",
    "                scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "                print(\"[train]\")\n",
    "            else:\n",
    "                if (epoch+1)%5==0:\n",
    "                    net.eval()\n",
    "                    print(\"[val]\")\n",
    "                else: \n",
    "                    continue\n",
    "            count=0\n",
    "            for imgs,anno_class_imgs in dataloaders_dict[phase]:\n",
    "                if imgs.size()[0]==1:\n",
    "                    continue\n",
    "                imgs=imgs.to(device)\n",
    "                anno_class_imgs=anno_class_imgs.to(device)\n",
    "\n",
    "                if phase=='train' and count==0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    count=batch_multiplier\n",
    "                    with torch.set_grad_enabled(phase==\"train\"):\n",
    "                        outputs=net(imgs)\n",
    "                        loss=criterion(outputs,anno_class_imgs.long())/batch_multiplier\n",
    "                        if phase==\"train\":\n",
    "                            loss.backward()\n",
    "                            count-=1\n",
    "                            if iteration%10==0:\n",
    "                                t_iter_finish=time.time()\n",
    "                                print(\"iter [{}] loss:{:.4f}   | {:.4f}sec\",iteration,loss.item()/batch_size*batch_multiplier,t_iter_finish-t_iter_start)\n",
    "                                t_iter_start=time.time()\n",
    "                            epoch_train_loss+=loss.item()*batch_multiplier\n",
    "                            iteration+=1\n",
    "                        else:\n",
    "                            epoch_val_loss+=loss.item()*batch_multiplier\n",
    "            t_epoch_finish=time.time()\n",
    "            print(\"epoch [{}] train loss:{:.4f}, val loss:{:.4f}  | {:.4f}sec\",iteration,epoch_train_loss/num_train_imgs,epoch_val_loss/num_val_imgs,t_epoch_finish-t_epoch_start)\n",
    "            t_epoch_start=time.time()\n",
    "\n",
    "            log_epoch={'epoch':epoch+1,'train_loss':epoch_train_loss/num_train_imgs,'val_loss':epoch_val_loss/num_val_imgs}\n",
    "            logs.append(log_epoch)\n",
    "            df=pd.DataFrame(logs)\n",
    "            df.to_csv('log_output.csv')\n",
    "        torch.save(net.state_dict(),'weights/pspnet50_'+str(epoch+1)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "Epoch 1/30\n",
      "[train]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/kist/nimod/pytorch deep learning/3_semantic_segmentation/3-training.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/3-training.ipynb#ch0000008?line=0'>1</a>\u001b[0m num_epochs\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/3-training.ipynb#ch0000008?line=1'>2</a>\u001b[0m train_model(net,dataloaders_dict,criterion,scheduler,optimizer,num_epochs)\n",
      "\u001b[1;32m/home/kist/nimod/pytorch deep learning/3_semantic_segmentation/3-training.ipynb Cell 7'\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(net, dataloaders_dict, criterion, scheduler, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/3-training.ipynb#ch0000007?line=46'>47</a>\u001b[0m count\u001b[39m=\u001b[39mbatch_multiplier\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/3-training.ipynb#ch0000007?line=47'>48</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mset_grad_enabled(phase\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/3-training.ipynb#ch0000007?line=48'>49</a>\u001b[0m     outputs\u001b[39m=\u001b[39mnet(imgs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/3-training.ipynb#ch0000007?line=49'>50</a>\u001b[0m     loss\u001b[39m=\u001b[39mcriterion(outputs,anno_class_imgs\u001b[39m.\u001b[39mlong())\u001b[39m/\u001b[39mbatch_multiplier\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/3-training.ipynb#ch0000007?line=50'>51</a>\u001b[0m     \u001b[39mif\u001b[39;00m phase\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/nimod/pytorch deep learning/3_semantic_segmentation/pspnet.py:242\u001b[0m, in \u001b[0;36mPSPNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=238'>239</a>\u001b[0m output_aux \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maux(x)\n\u001b[1;32m    <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=240'>241</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_dilated_res_2(x)\n\u001b[0;32m--> <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=241'>242</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyramid_pooling(x)\n\u001b[1;32m    <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=242'>243</a>\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode_feature(x)\n\u001b[1;32m    <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=244'>245</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (output, output_aux)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/nimod/pytorch deep learning/3_semantic_segmentation/pspnet.py:162\u001b[0m, in \u001b[0;36mPyramidPooling.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=159'>160</a>\u001b[0m outList \u001b[39m=\u001b[39m [x]\n\u001b[1;32m    <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=160'>161</a>\u001b[0m \u001b[39mfor\u001b[39;00m pool, cbr \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavpool, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcbr):\n\u001b[0;32m--> <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=161'>162</a>\u001b[0m     out \u001b[39m=\u001b[39m cbr(pool(x))\n\u001b[1;32m    <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=162'>163</a>\u001b[0m     out \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39minterpolate(\n\u001b[1;32m    <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=163'>164</a>\u001b[0m         out, size\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mheight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwidth), mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbilinear\u001b[39m\u001b[39m\"\u001b[39m, align_corners\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=164'>165</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=165'>166</a>\u001b[0m     outList\u001b[39m.\u001b[39mappend(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/nimod/pytorch deep learning/3_semantic_segmentation/pspnet.py:18\u001b[0m, in \u001b[0;36mconv2DBatchNormRelu.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=17'>18</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv(x)\n\u001b[1;32m     <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=18'>19</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatchnorm(x)\n\u001b[1;32m     <a href='file:///home/kist/nimod/pytorch%20deep%20learning/3_semantic_segmentation/pspnet.py?line=19'>20</a>\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=446'>447</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///home/kist/anaconda3/envs/pytorchDeepLearning/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=443'>444</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
     ]
    }
   ],
   "source": [
    "num_epochs=30\n",
    "train_model(net,dataloaders_dict,criterion,scheduler,optimizer,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "415c659548b03e5a7ab126dcfbb4fc7162127f64c5d6abf067896d088a8939b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorchDeepLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
