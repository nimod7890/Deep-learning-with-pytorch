{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class makeDatapathList():\n",
    "    def __init__(self, rootpath):\n",
    "        self.rootpath=rootpath\n",
    "        self.img_path_template=osp.join(rootpath,'JPEGImage','%s.jpg')\n",
    "        self.anno_path_template=osp.join(rootpath,'SegmentationClass','%s.png')\n",
    "    \n",
    "    def make_list(self,phase):\n",
    "        id_names=osp.join(self.rootpath+f\"ImageSets/Segmentation/{phase}.txt\")\n",
    "        img_list=[]\n",
    "        anno_list=[]\n",
    "        for line in open(id_names):\n",
    "            file_id=line.strip()\n",
    "            img_list.append(self.img_path_template%file_id)\n",
    "            anno_list.append(self.anno_path_template%file_id)\n",
    "        return [img_list,anno_list]\n",
    "\n",
    "    def __call__(self,phase):\n",
    "        return self.make_list(phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootpath='./data/VOCdevkit/VOC2012/'\n",
    "datapath_list=makeDatapathList(rootpath)\n",
    "train_img_list,train_anno_list=datapath_list('train')\n",
    "val_img_list,val_anno_list=datapath_list('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''check'''\n",
    "len(train_img_list),len(train_anno_list),len(val_img_list),len(val_anno_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_augumentation import Compose,Scale,RandomRotation,RandomMirror,Resize,Normalize_Tensor\n",
    "\n",
    "class dataTransform():\n",
    "    def __init__(self,input_size,color_mean,color_std):\n",
    "        self.data_transform={\n",
    "            'train':Compose([\n",
    "                Scale(scale=[0.5,1.5]),\n",
    "                RandomRotation(angle=[-10,10]),\n",
    "                RandomMirror(),\n",
    "                Resize(input_size),\n",
    "                Normalize_Tensor(color_mean,color_std)\n",
    "            ]),\n",
    "            'val':Compose([\n",
    "                Resize(input_size),\n",
    "                Normalize_Tensor(color_mean,color_std)\n",
    "            ])\n",
    "        }\n",
    "    def __call__(self,phase,img,anno_class_img):\n",
    "        return self.data_transform[phase](img,anno_class_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDataset(data.Dataset):\n",
    "    def __init__(self,img_list,anno_list,phase,transform):\n",
    "        self.img_list=img_list\n",
    "        self.anno_list=anno_list\n",
    "        self.phase=phase\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img,anno_class_img=self.pull_item(index)\n",
    "        return img,anno_class_img\n",
    "    \n",
    "    def pull_item(self,index):\n",
    "        img_file_path=self.img_list[index]\n",
    "        img=Image.open(img_file_path)\n",
    "        \n",
    "        anno_file_path=self.anno_list[index]\n",
    "        anno_class_img=Image.open(anno_file_path)\n",
    "        img,anno_class_img=self.transform(self.phase,img,anno_class_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''check'''\n",
    "color_mean=(0.485,0.456,0.406)\n",
    "color_std=(0.229,0.224,0.225)\n",
    "\n",
    "train_dataset=VOCDataset(train_img_list,train_anno_list,phase=\"train\",transform=dataTransform(input_size=475,color_mean=color_mean,color_std=color_std))\n",
    "val_dataset=VOCDataset(val_img_list,val_anno_list,phase=\"val\",transform=dataTransform(input_size=475,color_mean=color_mean,color_std=color_std))\n",
    "\n",
    "print(train_dataset.__getitem__(0)[0].shape,train_dataset.__getitem__(0)[1].shape)\n",
    "print(val_dataset.__getitem__(0)[0].shape,val_dataset.__getitem__(0)[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=0\n",
    "train_dataloader=data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "val_dataloader=data.DataLoader(val_dataset,batch_size=batch_size,shuffle=True)\n",
    "datalodaers_dict={\"train\":train_dataloader,\"val\":val_dataloader}\n",
    "batch_iterator=iter(datalodaers_dict[\"val\"])\n",
    "imgs,anno_class_imgs=next(batch_iterator)\n",
    "print(imgs.size())\n",
    "print(anno_class_imgs.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "415c659548b03e5a7ab126dcfbb4fc7162127f64c5d6abf067896d088a8939b1"
  },
  "kernelspec": {
   "display_name": "pytorchDeepLearning",
   "language": "python",
   "name": "pytorchdeeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
